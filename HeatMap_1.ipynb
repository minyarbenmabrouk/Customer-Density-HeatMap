{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LjAWG8rSY_rt",
        "9Uu-HhIQZPCF",
        "KWNJRl63ZhEr",
        "EiSo6LPih6D1",
        "DkXRFtqykxjm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmJNZuGRZr67",
        "outputId": "cd589daf-5072-4868-89f3-09e1dadbcc5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essai 1 traking images"
      ],
      "metadata": {
        "id": "LjAWG8rSY_rt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8KLyc2bY-h6"
      },
      "outputs": [],
      "source": [
        "#Lister le contenu du dossier\n",
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/fluxcustomer\"\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "print(\"Fichiers dans le dossier :\", files)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vérifier l'annotation de dataset\n",
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def draw_annotations(image_path, label_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    with open(label_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        data = line.strip().split()\n",
        "        class_id, x, y, width, height = map(float, data)\n",
        "\n",
        "        # Convertir YOLO format en pixels\n",
        "        x1 = int((x - width / 2) * w)\n",
        "        y1 = int((y - height / 2) * h)\n",
        "        x2 = int((x + width / 2) * w)\n",
        "        y2 = int((y + height / 2) * h)\n",
        "\n",
        "        # Dessiner la boîte englobante\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    cv2_imshow(img)\n",
        "\n",
        "def process_dataset(dataset_type):\n",
        "    image_folder = f\"/content/drive/MyDrive/fluxcustomer/{dataset_type}/images\"\n",
        "    label_folder = f\"/content/drive/MyDrive/fluxcustomer/{dataset_type}/labels\"\n",
        "\n",
        "    # Lister et trier les fichiers d'annotations\n",
        "    label_files = sorted(os.listdir(label_folder))[:5]\n",
        "\n",
        "    for label_file in label_files:\n",
        "        if label_file.endswith(\".txt\"):\n",
        "            image_file = label_file.replace(\".txt\", \".jpg\")\n",
        "            image_path = os.path.join(image_folder, image_file)\n",
        "            label_path = os.path.join(label_folder, label_file)\n",
        "\n",
        "            if os.path.exists(image_path):\n",
        "                draw_annotations(image_path, label_path)\n",
        "            else:\n",
        "                print(f\"Image non trouvée pour {label_file}\")\n",
        "\n",
        "# Exécuter la fonction pour chaque dataset\n",
        "for dataset in [\"train\", \"valid\", \"test\"]:\n",
        "    print(f\"\\nAffichage des annotations pour {dataset}:\")\n",
        "    process_dataset(dataset)"
      ],
      "metadata": {
        "id": "neeMFflDZMw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujVVcg7sgai6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image processing**"
      ],
      "metadata": {
        "id": "qggvUPB9ga3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vérifier la taille de quelques images\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Dossier des images\n",
        "image_folder = \"/content/drive/MyDrive/fluxcustomer/train/images\"\n",
        "\n",
        "# Liste des fichiers images\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "\n",
        "# Afficher la taille des 10 premières images\n",
        "for i, image_name in enumerate(image_files[:10]):  # Prendre les 10 premières images\n",
        "    image_path = os.path.join(image_folder, image_name)\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is not None:\n",
        "        h, w, c = img.shape  # Hauteur, largeur, nombre de canaux\n",
        "        print(f\"Image {i+1}: {image_name} → Taille: {w}x{h}, Canaux: {c}\")\n",
        "    else:\n",
        "        print(f\"Image {i+1}: {image_name} → Impossible de charger l'image.\")"
      ],
      "metadata": {
        "id": "ETHM94CYZzBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prétraitement → Entraînement YOLOv5**"
      ],
      "metadata": {
        "id": "CDHu6Rn7gj2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation et Configuration de YOLOv5\n",
        "# Clone le repo YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "\n",
        "# Installer les dépendances\n",
        "%pip install -qr requirements.txt\n",
        "%pip install -q roboflow"
      ],
      "metadata": {
        "id": "Gk2SFsYjZzEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vérifie que l'installation est correcte\n",
        "import torch\n",
        "print(f\"Using torch {torch.__version__} ({'CUDA' if torch.cuda.is_available() else 'CPU'})\")\n"
      ],
      "metadata": {
        "id": "7TVHjwDRZzGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prétraitement des Images et Labels (Redimensionnement 640x640)**"
      ],
      "metadata": {
        "id": "ThNpVhfTgtZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Fonction pour redimensionner tout en conservant les proportions\n",
        "def resize_image_keep_aspect(image, target_size):\n",
        "    h, w, _ = image.shape\n",
        "    scale = target_size / max(h, w)  # Calcul du facteur d’échelle\n",
        "    new_w, new_h = int(w * scale), int(h * scale)  # Nouvelles dimensions\n",
        "    resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # Ajouter des bordures pour atteindre 640x640\n",
        "    top = (target_size - new_h) // 2\n",
        "    bottom = target_size - new_h - top\n",
        "    left = (target_size - new_w) // 2\n",
        "    right = target_size - new_w - left\n",
        "\n",
        "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))\n",
        "\n",
        "    return padded_image, scale, left, top\n",
        "\n",
        "# Dossiers principaux\n",
        "base_folder = \"/content/drive/MyDrive/fluxcustomer\"\n",
        "datasets = [\"train\", \"valid\",\"test\"]  # Appliquer le traitement sur train et valid et test\n",
        "\n",
        "target_size = 640  # Taille cible\n",
        "\n",
        "for dataset in datasets:\n",
        "    image_folder = os.path.join(base_folder, dataset, \"images\")\n",
        "    label_folder = os.path.join(base_folder, dataset, \"labels\")\n",
        "    output_image_folder = os.path.join(base_folder, dataset, \"resized_images\")\n",
        "    output_label_folder = os.path.join(base_folder, dataset, \"resized_labels\")\n",
        "\n",
        "    # Assurez-vous que les dossiers de sortie existent\n",
        "    os.makedirs(output_image_folder, exist_ok=True)\n",
        "    os.makedirs(output_label_folder, exist_ok=True)\n",
        "\n",
        "    # Parcourir toutes les images\n",
        "    image_paths = glob.glob(os.path.join(image_folder, \"*.jpg\"))  # Changez l'extension si nécessaire\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        filename = os.path.basename(image_path)\n",
        "        label_path = os.path.join(label_folder, filename.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "        # Charger l’image\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            print(f\" Impossible de lire {image_path}, ignoré.\")\n",
        "            continue\n",
        "\n",
        "        # Redimensionner l’image\n",
        "        resized_img, scale, left_pad, top_pad = resize_image_keep_aspect(img, target_size)\n",
        "\n",
        "        # Sauvegarder l’image redimensionnée\n",
        "        cv2.imwrite(os.path.join(output_image_folder, filename), resized_img)\n",
        "\n",
        "        # Ajuster et sauvegarder l’annotation si elle existe\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            new_lines = []\n",
        "            for line in lines:\n",
        "                data = line.strip().split()\n",
        "                class_id = data[0]\n",
        "                x, y, width, height = map(float, data[1:])\n",
        "\n",
        "                # Conversion des coordonnées avec l'échelle et le padding\n",
        "                new_x = (x * img.shape[1] * scale + left_pad) / target_size\n",
        "                new_y = (y * img.shape[0] * scale + top_pad) / target_size\n",
        "                new_width = (width * img.shape[1] * scale) / target_size\n",
        "                new_height = (height * img.shape[0] * scale) / target_size\n",
        "\n",
        "                new_lines.append(f\"{class_id} {new_x:.6f} {new_y:.6f} {new_width:.6f} {new_height:.6f}\\n\")\n",
        "\n",
        "            # Sauvegarde du fichier d’annotation modifié\n",
        "            with open(os.path.join(output_label_folder, filename.replace(\".jpg\", \".txt\")), \"w\") as f:\n",
        "                f.writelines(new_lines)\n",
        "\n",
        "        print(f\" {dataset}: {filename} redimensionné et sauvegardé !\")\n",
        "\n",
        "print(\" Redimensionnement terminé pour TRAIN et VALID et TEST !\")"
      ],
      "metadata": {
        "id": "PHNoC9WAZzKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "#  Dossiers des images et annotations après redimensionnement\n",
        "datasets = [\"train\", \"valid\", \"test\"]\n",
        "base_path = \"/content/drive/MyDrive/fluxcustomer\"\n",
        "\n",
        "#  Fonction pour dessiner les annotations\n",
        "def draw_annotations(image_path, label_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\" Impossible de lire {image_path}\")\n",
        "        return\n",
        "\n",
        "    h, w, _ = img.shape  # Toujours 640x640 après redimensionnement\n",
        "\n",
        "    with open(label_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        data = line.strip().split()\n",
        "        class_id, x, y, width, height = map(float, data)\n",
        "\n",
        "        # Convertir YOLO format en pixels\n",
        "        x1 = int((x - width / 2) * w)\n",
        "        y1 = int((y - height / 2) * h)\n",
        "        x2 = int((x + width / 2) * w)\n",
        "        y2 = int((y + height / 2) * h)\n",
        "\n",
        "        #  Dessiner la boîte englobante\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    cv2_imshow(img)  #  Afficher l'image annotée\n",
        "\n",
        "#  Afficher les annotations pour chaque ensemble (train, valid, test)\n",
        "for dataset in datasets:\n",
        "    print(f\"\\n Affichage des annotations pour {dataset} \\n\")\n",
        "\n",
        "    output_image_folder = os.path.join(base_path, dataset, \"resized_images\")\n",
        "    output_label_folder = os.path.join(base_path, dataset, \"resized_labels\")\n",
        "\n",
        "    if not os.path.exists(output_label_folder):\n",
        "        print(f\" Dossier {output_label_folder} non trouvé, passage à l'ensemble suivant...\")\n",
        "        continue\n",
        "\n",
        "    #  Lister et trier les fichiers d'annotations\n",
        "    label_files = sorted(os.listdir(output_label_folder))[:5]  # Ne garder que les 5 premiers fichiers\n",
        "\n",
        "    for label_file in label_files:\n",
        "        if label_file.endswith(\".txt\"):\n",
        "            image_file = label_file.replace(\".txt\", \".jpg\")  # Adapter selon l'extension réelle\n",
        "            image_path = os.path.join(output_image_folder, image_file)\n",
        "            label_path = os.path.join(output_label_folder, label_file)\n",
        "\n",
        "            if os.path.exists(image_path):\n",
        "                print(f\" Affichage de {image_file} avec annotations \")\n",
        "                draw_annotations(image_path, label_path)\n",
        "            else:\n",
        "                print(f\" Image non trouvée pour {label_file}\")\n"
      ],
      "metadata": {
        "id": "s-rTA8thZzMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entraînement de YOLOv5 **"
      ],
      "metadata": {
        "id": "-8U2c6x0haU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 50 --data /content/drive/MyDrive/fluxcustomer/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "id": "TRvP0BM8ZzPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer les performances du modèle\n",
        "!python val.py --weights runs/train/exp/weights/best.pt --data /content/drive/MyDrive/fluxcustomer/data.yaml --img 640"
      ],
      "metadata": {
        "id": "Fz6ngXRUZzRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tester une image\n",
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --source /content/drive/MyDrive/fluxcustomer/test/images/ --conf 0.25"
      ],
      "metadata": {
        "id": "HsA5mnnbZzS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Étape 2 : Suivi des clients avec DeepSORT**"
      ],
      "metadata": {
        "id": "89sJe4mPhhyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Sharpiless/Yolov5-deepsort-inference.git\n",
        "\n",
        "%cd Yolov5-deepsort-inference\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "H8b2pfKIZzU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/drive/MyDrive/fluxcustomer/train/images\"  # Dossier contenant les images\n",
        "video_name = \"/content/drive/MyDrive/fluxcustomer/output_video.mp4\"  # Vidéo de sortie\n",
        "\n",
        "images = sorted(os.listdir(image_folder))  # Trier les images par nom\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec vidéo\n",
        "video = cv2.VideoWriter(video_name, fourcc, 10, (width, height))  # 10 FPS\n",
        "\n",
        "for image in images:\n",
        "    img_path = os.path.join(image_folder, image)\n",
        "    frame = cv2.imread(img_path)\n",
        "    video.write(frame)\n",
        "\n",
        "video.release()\n",
        "print(f\"Vidéo créée: {video_name}\")"
      ],
      "metadata": {
        "id": "1oxodMbKZzWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Video\n",
        "\n",
        "video_path = \"/content/drive/MyDrive/fluxcustomer/output_video.mp4\"\n",
        "display(Video(video_path))\n"
      ],
      "metadata": {
        "id": "XOq6XDgrhn3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BH9yQSfhn57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ZQPei/deep_sort_pytorch.git  # Exemple avec deep_sort_pytorch\n",
        "%cd deep_sort_pytorch\n",
        "\n",
        "\n",
        "!pip install numpy opencv-python scipy\n",
        "import torch\n",
        "print(torch.__version__)  # Affiche la version de PyTorch installée"
      ],
      "metadata": {
        "id": "-jSIXSi5hn8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import imutils\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort"
      ],
      "metadata": {
        "id": "cIjnd8fKhn-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloner DeepSORT\n",
        "!git clone https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch.git\n",
        "%cd Yolov5_DeepSort_Pytorch\n",
        "!pip3 install -U pip\n",
        "!pip3 install -qr requirements.txt\n",
        "#!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ywTttAighoAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/KaiyangZhou/deep-person-reid/releases/download/v1.0.0/osnet_x1_0_imagenet.pth"
      ],
      "metadata": {
        "id": "CLboC0k4hoC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6wA5VOO9i1DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QYHGMGYLi1IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "from ultralytics import YOLO\n",
        "import imutils\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def processVideo():\n",
        "    counter_cache = []\n",
        "    detection_classes = []\n",
        "    count = 0\n",
        "    path = \"/content/drive/MyDrive/fluxcustomer/video/season-sale-with-crowd-of-people-on-escalator-in-shopping-mall-SBV-319088788-preview.mp4\"\n",
        "\n",
        "    # Lire la vidéo\n",
        "    vs = cv.VideoCapture(path)\n",
        "\n",
        "    # Charger le modèle YOLOv8\n",
        "    model = YOLO('yolov8n.pt')\n",
        "\n",
        "    # Configurer DeepSort pour le suivi\n",
        "    object_tracker = DeepSort(max_iou_distance=0.7,\n",
        "                               max_age=5,\n",
        "                               n_init=3,\n",
        "                               nms_max_overlap=1.0,\n",
        "                               max_cosine_distance=0.2,\n",
        "                               nn_budget=None,\n",
        "                               gating_only_position=False,\n",
        "                               override_track_class=None,\n",
        "                               embedder=\"mobilenet\",\n",
        "                               half=True,\n",
        "                               bgr=True,\n",
        "                               embedder_gpu=True,\n",
        "                               embedder_model_name=None,\n",
        "                               embedder_wts=None,\n",
        "                               polygon=False,\n",
        "                               today=None\n",
        "                               )\n",
        "\n",
        "    while True:\n",
        "        (grabbed, frame) = vs.read()\n",
        "        if not grabbed:\n",
        "            break\n",
        "\n",
        "        # Détection des personnes uniquement (classe 0)\n",
        "        results = model.predict(frame, stream=False, classes=[0])\n",
        "        print(results[0].names)\n",
        "        detection_classes = results[0].names\n",
        "        frame = draw_line(frame)\n",
        "\n",
        "        for result in results:\n",
        "            for data in result.boxes.data.tolist():\n",
        "                id = int(data[5])\n",
        "\n",
        "                # Vérifier si c'est une personne\n",
        "                if id == 0:\n",
        "                    drawBox(data, frame, detection_classes[id])\n",
        "                    print(\"Detected Class:\", detection_classes[id])\n",
        "\n",
        "            # Obtenir les détails pour le suivi\n",
        "            details = get_details(result, frame)\n",
        "            tracks = object_tracker.update_tracks(details, frame=frame)\n",
        "\n",
        "        # Suivi et comptage\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            track_id = track.track_id\n",
        "            bbox = track.to_ltrb()\n",
        "\n",
        "            cv.putText(frame, f\"ID: {track_id}\", (int(bbox[0]), int(bbox[1])), cv.FONT_HERSHEY_SIMPLEX, 1,\n",
        "                       (0, 255, 0), 6)\n",
        "            cv.putText(frame, f\"Person Count: {count}\", (100, 100), cv.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 9)\n",
        "\n",
        "            # Compter les personnes traversant la ligne\n",
        "            if bbox[1] > int(frame.shape[0] / 2) and track_id not in counter_cache:\n",
        "                counter_cache.append(track_id)\n",
        "                count += 1\n",
        "                cv.putText(frame, f\"Person Count: {count}\", (100, 100), cv.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 9)\n",
        "\n",
        "        # Afficher la vidéo\n",
        "        cv.imshow('image', frame)\n",
        "        if cv.waitKey(30) & 0xFF == 27:  # Appuyez sur 'ESC' pour quitter\n",
        "            break\n",
        "\n",
        "    vs.release()\n",
        "    cv.destroyAllWindows()\n",
        "\n",
        "\n",
        "def drawBox(data, image, name):\n",
        "    x1, y1, x2, y2, conf, id = data\n",
        "    p1 = (int(x1), int(y1))\n",
        "    p2 = (int(x2), int(y2))\n",
        "\n",
        "    # Dessiner la boîte et afficher le nom\n",
        "    cv.rectangle(image, p1, p2, (0, 0, 255), 3)\n",
        "    cv.putText(image, name, p1, cv.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 3)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def get_details(result, image):\n",
        "    classes = result.boxes.cls.numpy()\n",
        "    conf = result.boxes.conf.numpy()\n",
        "    xywh = result.boxes.xywh.numpy()\n",
        "\n",
        "    detections = []\n",
        "    for i, item in enumerate(xywh):\n",
        "        sample = (item, conf[i], classes[i])\n",
        "        detections.append(sample)\n",
        "\n",
        "    return detections\n",
        "\n",
        "\n",
        "def draw_line(image):\n",
        "    depth = int(image.shape[0] / 2)\n",
        "    p1 = (400, depth)\n",
        "    p2 = (image.shape[1] - 200, depth)\n",
        "\n",
        "    # Dessiner la ligne verte au milieu\n",
        "    image = cv.line(image, p1, p2, (0, 255, 0), thickness=10)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "# Lancer la fonction principale\n",
        "processVideo()"
      ],
      "metadata": {
        "id": "arDtQnsJi1Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aliIX-aoi1Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7mE3OOwfi1u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "A94yqQMZhoFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "print(ultralytics.__version__)"
      ],
      "metadata": {
        "id": "p3btx7ghhoHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "# Charger le modèle YOLOv8\n",
        "model = YOLO(\"yolov8l.pt\")\n",
        "\n",
        "# Ouvrir la vidéo\n",
        "path = \"/content/drive/MyDrive/fluxcustomer/video/season-sale-with-crowd-of-people-on-escalator-in-shopping-mall-SBV-319088788-preview.mp4\"\n",
        "vs = cv.VideoCapture(path)\n",
        "\n",
        "# Initialiser la vidéo de sortie\n",
        "writer = None\n",
        "frame_number = 0\n",
        "\n",
        "while True:\n",
        "    grabbed, frame = vs.read()\n",
        "    if not grabbed:\n",
        "        break\n",
        "\n",
        "    # Appliquer le suivi sur la frame actuelle\n",
        "    results = model.track(frame)  # Obtenez les résultats du suivi\n",
        "\n",
        "    # Créer une heatmap vide avec la même taille que l'image\n",
        "    heatmap = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.float32)\n",
        "\n",
        "    # Parcourez les résultats et ajoutez les informations de position à la heatmap\n",
        "    for result in results:\n",
        "        for box in result.boxes.xyxy:  # Assurez-vous que cette partie correspond à la structure du résultat\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            # Ajoutez de la chaleur à la position de l'objet (par exemple, une valeur de chaleur)\n",
        "            heatmap[y1:y2, x1:x2] += 1\n",
        "\n",
        "    # Normalisez la heatmap pour qu’elle ait des valeurs comprises entre 0 et 255\n",
        "    heatmap = cv.normalize(heatmap, None, 0, 255, cv.NORM_MINMAX)\n",
        "    heatmap = np.uint8(heatmap)\n",
        "\n",
        "    # Appliquez une colormap (par exemple, Parula) pour colorier la heatmap\n",
        "    heatmap_color = cv.applyColorMap(heatmap, cv.COLORMAP_PARULA)\n",
        "\n",
        "    # Fusionner la heatmap avec l'image originale (optionnel)\n",
        "    frame_with_heatmap = cv.addWeighted(frame, 0.7, heatmap_color, 0.3, 0)\n",
        "\n",
        "    # Afficher l'image avec la heatmap\n",
        "    cv2_imshow(frame_with_heatmap)\n",
        "\n",
        "\n",
        "    # Enregistrer la vidéo avec la heatmap\n",
        "    if writer is None:\n",
        "        fourcc = cv.VideoWriter_fourcc(*\"MJPG\")\n",
        "        writer = cv.VideoWriter(\"people_mall_with_heatmap.mp4\", fourcc, 24,\n",
        "                                (frame.shape[1], frame.shape[0]), True)\n",
        "    writer.write(frame_with_heatmap)\n",
        "\n",
        "    # Attendre un peu pour afficher chaque frame\n",
        "    if cv.waitKey(24) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Fermer le fichier vidéo et les fenêtres\n",
        "vs.release()\n",
        "writer.release()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "yG10RQK3h5AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# Charger le modèle YOLO entraîné\n",
        "model = YOLO('yolov8n.pt')\n",
        "#model = YOLO(\"runs/train/exp/weights/best.pt\")\n",
        "\n",
        "# Initialiser DeepSORT\n",
        "tracker = DeepSort(max_age=30)  # max_age définit combien de frames un ID reste actif sans détection\n",
        "\n",
        "# Dossier contenant les images\n",
        "image_folder =  \"/content/drive/MyDrive/fluxcustomer/train/images\"\n",
        "output_folder = \"/content/drive/MyDrive/fluxcustomer/output\"  # Dossier où enregistrer les images traitées\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Parcourir les images et appliquer YOLO + DeepSORT\n",
        "for image_name in sorted(os.listdir(image_folder)):  # Trier pour garder l'ordre\n",
        "    if image_name.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "        image_path = os.path.join(image_folder, image_name)\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        # Détection avec YOLO\n",
        "        results = model(image_path)\n",
        "\n",
        "        detections = []\n",
        "        for r in results:\n",
        "            for box in r.boxes:\n",
        "                if int(box.cls[0]) in [0, 1]:  # Seulement \"female\" et \"male\"\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                    confidence = float(box.conf[0])\n",
        "                    detections.append([[x1, y1, x2, y2], confidence, int(box.cls[0])])\n",
        "\n",
        "        # Mise à jour du tracker\n",
        "        tracks = tracker.update_tracks(detections, frame=img)\n",
        "\n",
        "        # Dessiner les boîtes avec ID\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            track_id = track.track_id\n",
        "            ltrb = track.to_ltrb()\n",
        "            x1, y1, x2, y2 = map(int, ltrb)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "            cv2.putText(img, f\"ID {track_id}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        # Sauvegarde de l'image annotée\n",
        "        output_path = os.path.join(output_folder, image_name)\n",
        "        cv2.imwrite(output_path, img)\n",
        "\n",
        "        print(f\"Image {image_name} traitée avec suivi !\")"
      ],
      "metadata": {
        "id": "JKZ9YUTfh5Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dossier contenant les images annotées après suivi avec DeepSORT\n",
        "output_folder = \"/content/drive/MyDrive/fluxcustomer/output\"\n",
        "\n",
        "# Taille commune pour redimensionner les images\n",
        "target_size = (640, 360)  # (largeur, hauteur)\n",
        "\n",
        "# Initialiser la heatmap\n",
        "heatmap = None\n",
        "count = 0  # Compteur pour normalisation\n",
        "\n",
        "# Parcourir toutes les images annotées\n",
        "for image_name in os.listdir(output_folder):\n",
        "    if image_name.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "        image_path = os.path.join(output_folder, image_name)\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Charger en couleur\n",
        "\n",
        "        # Redimensionner l'image à la taille cible\n",
        "        img_resized = cv2.resize(img, target_size)\n",
        "\n",
        "        # Convertir l'image en niveaux de gris pour le seuillage\n",
        "        gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Seuillage pour détecter les objets (par exemple, les annotations en blanc)\n",
        "        _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Initialiser la heatmap si ce n'est pas déjà fait\n",
        "        if heatmap is None:\n",
        "            heatmap = np.zeros((target_size[1], target_size[0]), dtype=np.float32)  # (hauteur, largeur)\n",
        "\n",
        "        # Ajouter les positions des objets détectés sur la heatmap\n",
        "        heatmap += (thresh / 255).astype(np.float32)  # Ajouter 1 pour chaque pixel détecté\n",
        "\n",
        "        count += 1\n",
        "\n",
        "# Normalisation et application de la colormap\n",
        "if count > 0:\n",
        "    heatmap = (heatmap / np.max(heatmap)) * 255  # Normaliser par la valeur maximale\n",
        "    heatmap = heatmap.astype(np.uint8)\n",
        "\n",
        "    # Appliquer un colormap (HOT pour une meilleure visibilité)\n",
        "    heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_HOT)\n",
        "\n",
        "    # Charger une image représentative du magasin (par exemple, la première image)\n",
        "    background_image_path = os.path.join(output_folder, os.listdir(output_folder)[0])\n",
        "    background = cv2.imread(background_image_path)\n",
        "    background_resized = cv2.resize(background, target_size)\n",
        "\n",
        "    # Superposer la heatmap sur l'image originale avec transparence\n",
        "    alpha = 0.5  # Transparence de la heatmap (ajuster selon les besoins)\n",
        "    overlayed = cv2.addWeighted(background_resized, 1 - alpha, heatmap_colored, alpha, 0)\n",
        "\n",
        "    # Sauvegarde et affichage de la heatmap superposée\n",
        "    heatmap_path = os.path.join(output_folder, \"heatmap_overlayed.jpg\")\n",
        "    cv2.imwrite(heatmap_path, overlayed)\n",
        "\n",
        "    # Affichage avec Matplotlib\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(cv2.cvtColor(overlayed, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Carte de Densité des Clients (Superposée)\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"✅ Heatmap superposée générée et sauvegardée ici : {heatmap_path}\")\n",
        "else:\n",
        "    print(\"⚠️ Aucune image détectée pour la génération de la Heatmap !\")\n"
      ],
      "metadata": {
        "id": "LuoXBlEdh5F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dossier contenant les images annotées après suivi avec DeepSORT\n",
        "output_folder = \"/content/drive/MyDrive/fluxcustomer/output\"\n",
        "\n",
        "# Taille commune pour redimensionner les images\n",
        "target_size = (640, 360)  # (largeur, hauteur)\n",
        "\n",
        "# Nombre de heatmaps à générer\n",
        "num_heatmaps = 4\n",
        "\n",
        "# Initialiser une liste pour stocker les heatmaps\n",
        "heatmaps = [np.zeros((target_size[1], target_size[0]), dtype=np.float32) for _ in range(num_heatmaps)]\n",
        "\n",
        "# Compter le nombre d'images dans chaque groupe\n",
        "counts = [0] * num_heatmaps\n",
        "\n",
        "# Parcourir toutes les images annotées\n",
        "image_files = [f for f in os.listdir(output_folder) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "num_images = len(image_files)\n",
        "\n",
        "for i, image_name in enumerate(image_files):\n",
        "    image_path = os.path.join(output_folder, image_name)\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Charger en couleur\n",
        "\n",
        "    # Redimensionner l'image à la taille cible\n",
        "    img_resized = cv2.resize(img, target_size)\n",
        "\n",
        "    # Convertir l'image en niveaux de gris pour le seuillage\n",
        "    gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Seuillage pour détecter les objets (par exemple, les annotations en blanc)\n",
        "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Déterminer à quel groupe cette image appartient\n",
        "    group_index = i % num_heatmaps\n",
        "\n",
        "    # Ajouter les positions des objets détectés sur la heatmap du groupe correspondant\n",
        "    heatmaps[group_index] += (thresh / 255).astype(np.float32)  # Ajouter 1 pour chaque pixel détecté\n",
        "    counts[group_index] += 1\n",
        "\n",
        "# Normalisation et application de la colormap pour chaque heatmap\n",
        "for i in range(num_heatmaps):\n",
        "    if counts[i] > 0:\n",
        "        heatmaps[i] = (heatmaps[i] / np.max(heatmaps[i])) * 255  # Normaliser par la valeur maximale\n",
        "        heatmaps[i] = heatmaps[i].astype(np.uint8)\n",
        "\n",
        "# Créer une figure pour afficher les 4 heatmaps\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i in range(num_heatmaps):\n",
        "    # Appliquer un colormap (HOT pour une meilleure visibilité)\n",
        "    heatmap_colored = cv2.applyColorMap(heatmaps[i], cv2.COLORMAP_HOT)\n",
        "\n",
        "    # Charger une image représentative du magasin (par exemple, la première image)\n",
        "    background_image_path = os.path.join(output_folder, image_files[0])\n",
        "    background = cv2.imread(background_image_path)\n",
        "    background_resized = cv2.resize(background, target_size)\n",
        "\n",
        "    # Superposer la heatmap sur l'image originale avec transparence\n",
        "    alpha = 0.5  # Transparence de la heatmap (ajuster selon les besoins)\n",
        "    overlayed = cv2.addWeighted(background_resized, 1 - alpha, heatmap_colored, alpha, 0)\n",
        "\n",
        "    # Afficher la heatmap superposée\n",
        "    plt.subplot(2, 2, i + 1)  # 2 lignes, 2 colonnes\n",
        "    plt.imshow(cv2.cvtColor(overlayed, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Heatmap Groupe {i + 1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7gvM_Qavh5It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dossier contenant les images annotées après suivi avec DeepSORT\n",
        "output_folder = \"/content/drive/MyDrive/fluxcustomer/output\"\n",
        "\n",
        "# Taille commune pour redimensionner les images\n",
        "target_size = (640, 360)  # (largeur, hauteur)\n",
        "\n",
        "# Nombre de heatmaps à générer\n",
        "num_heatmaps = 4\n",
        "\n",
        "# Initialiser une liste pour stocker les heatmaps\n",
        "heatmaps = [np.zeros((target_size[1], target_size[0]), dtype=np.float32) for _ in range(num_heatmaps)]\n",
        "\n",
        "# Compter le nombre d'images dans chaque groupe\n",
        "counts = [0] * num_heatmaps\n",
        "\n",
        "# Parcourir toutes les images annotées\n",
        "image_files = [f for f in os.listdir(output_folder) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "num_images = len(image_files)\n",
        "\n",
        "for i, image_name in enumerate(image_files):\n",
        "    image_path = os.path.join(output_folder, image_name)\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Charger en couleur\n",
        "\n",
        "    # Redimensionner l'image à la taille cible\n",
        "    img_resized = cv2.resize(img, target_size)\n",
        "\n",
        "    # Convertir l'image en niveaux de gris pour le seuillage\n",
        "    gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Seuillage pour détecter les objets (par exemple, les annotations en blanc)\n",
        "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Déterminer à quel groupe cette image appartient\n",
        "    group_index = i % num_heatmaps\n",
        "\n",
        "    # Ajouter les positions des objets détectés sur la heatmap du groupe correspondant\n",
        "    heatmaps[group_index] += (thresh / 255).astype(np.float32)  # Ajouter 1 pour chaque pixel détecté\n",
        "    counts[group_index] += 1\n",
        "\n",
        "# Définir les seuils de densité\n",
        "density_thresholds = {\n",
        "    'red': 0.8,    # Forte densité\n",
        "    'yellow': 0.5, # Moyenne densité\n",
        "    'blue': 0.3,   # Faible densité\n",
        "    'green': 0.1   # Très faible densité\n",
        "}\n",
        "\n",
        "# Créer une figure pour afficher les 4 heatmaps\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i in range(num_heatmaps):\n",
        "    if counts[i] > 0:\n",
        "        # Normaliser la heatmap\n",
        "        heatmap_normalized = (heatmaps[i] / np.max(heatmaps[i]))\n",
        "\n",
        "        # Appliquer les couleurs en fonction des seuils de densité\n",
        "        heatmap_colored = np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8)\n",
        "        heatmap_colored[heatmap_normalized > density_thresholds['red']] = [0, 0, 255]    # Rouge\n",
        "        heatmap_colored[(heatmap_normalized > density_thresholds['yellow']) & (heatmap_normalized <= density_thresholds['red'])] = [0, 255, 255]  # Jaune\n",
        "        heatmap_colored[(heatmap_normalized > density_thresholds['blue']) & (heatmap_normalized <= density_thresholds['yellow'])] = [255, 0, 0]    # Bleu\n",
        "        heatmap_colored[heatmap_normalized <= density_thresholds['green']] = [0, 255, 0]  # Vert\n",
        "\n",
        "        # Charger une image représentative du magasin (par exemple, la première image)\n",
        "        background_image_path = os.path.join(output_folder, image_files[0])\n",
        "        background = cv2.imread(background_image_path)\n",
        "        background_resized = cv2.resize(background, target_size)\n",
        "\n",
        "        # Superposer la heatmap sur l'image originale avec transparence\n",
        "        alpha = 0.5  # Transparence de la heatmap (ajuster selon les besoins)\n",
        "        overlayed = cv2.addWeighted(background_resized, 1 - alpha, heatmap_colored, alpha, 0)\n",
        "\n",
        "        # Afficher la heatmap superposée\n",
        "        plt.subplot(2, 2, i + 1)  # 2 lignes, 2 colonnes\n",
        "        plt.imshow(cv2.cvtColor(overlayed, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"Heatmap Groupe {i + 1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gpk3ZfPMh5LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uRQQWGABh5Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fIjbzbSMh5Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DslLNY7nh5R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essai 2 traking images with deepsort"
      ],
      "metadata": {
        "id": "9Uu-HhIQZPCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lister le contenu du dossier\n",
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/fluxcustomer\"\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "print(\"Fichiers dans le dossier :\", files)"
      ],
      "metadata": {
        "id": "41VRjph3ZM1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics deep-sort-realtime opencv-python"
      ],
      "metadata": {
        "id": "UUwAZ-zpj0Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classe de tracking\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "\n",
        "class VideoTracker:\n",
        "    def __init__(self, model_path='yolov8n.pt', classes=[0], conf_threshold=0.5):\n",
        "\n",
        "        \"\"\"Initialise le tracker vidéo\n",
        "        Args:\n",
        "            model_path: Chemin vers le modèle YOLO\n",
        "            classes: Listes des classes à tracker (0=personne par défaut)\n",
        "            conf_threshold: Seuil de confiance minimum\"\"\"\n",
        "\n",
        "        self.model = YOLO(model_path)\n",
        "        self.tracker = DeepSort(max_age=30, n_init=3)\n",
        "        self.classes = classes\n",
        "        self.conf_threshold = conf_threshold\n",
        "\n",
        "    def track_video(self, input_path, output_path=None, show_frames=False, display_interval=10):\n",
        "\n",
        "\n",
        "       \"\"\" Effectue le tracking sur une vidéo\n",
        "        Args:\n",
        "            input_path: Chemin de la vidéo d'entrée\n",
        "            output_path: Chemin de sortie (None pour ne pas sauvegarder)\n",
        "            show_frames: Afficher les frames pendant le traitement\n",
        "            display_interval: Afficher 1 frame sur N\n",
        "        Returns:\n",
        "            stats: Dictionnaire de statistiques\"\"\"\n",
        "\n",
        "       cap = cv2.VideoCapture(input_path)\n",
        "       if not cap.isOpened():\n",
        "            raise ValueError(f\"Impossible d'ouvrir {input_path}\")\n",
        "\n",
        "        # Initialisation de la sortie vidéo\n",
        "       if output_path:\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            out = cv2.VideoWriter(output_path,\n",
        "                                cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                                fps, (width, height))\n",
        "       else:\n",
        "            out = None\n",
        "\n",
        "       frame_count = 0\n",
        "       start_time = time.time()\n",
        "       stats = {'total_frames': 0, 'processing_time': 0}\n",
        "\n",
        "       try:\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # Détection et tracking\n",
        "                results = self.model(frame, classes=self.classes, conf=self.conf_threshold)\n",
        "                detections = self._prepare_detections(results)\n",
        "                tracks = self.tracker.update_tracks(detections, frame=frame)\n",
        "                processed_frame = self._draw_tracks(frame, tracks)\n",
        "\n",
        "                # Sauvegarde\n",
        "                if out:\n",
        "                    out.write(processed_frame)\n",
        "\n",
        "                # Affichage\n",
        "                if show_frames and frame_count % display_interval == 0:\n",
        "                    cv2_imshow(processed_frame)\n",
        "\n",
        "                frame_count += 1\n",
        "\n",
        "       finally:\n",
        "            cap.release()\n",
        "            if out:\n",
        "                out.release()\n",
        "\n",
        "            stats['total_frames'] = frame_count\n",
        "            stats['processing_time'] = time.time() - start_time\n",
        "            stats['fps'] = frame_count / stats['processing_time'] if stats['processing_time'] > 0 else 0\n",
        "\n",
        "            return stats\n",
        "\n",
        "    def _prepare_detections(self, results):\n",
        "        #Convertit les résultats YOLO en format DeepSORT\n",
        "        detections = []\n",
        "        for r in results:\n",
        "            for box in r.boxes:\n",
        "                if box.conf.item() > self.conf_threshold:\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "                    detections.append([[x1, y1, x2, y2], box.conf.item(), int(box.cls[0])])\n",
        "        return detections\n",
        "\n",
        "    def _draw_tracks(self, frame, tracks):\n",
        "       # Dessine les tracks sur la frame\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "\n",
        "            track_id = track.track_id\n",
        "            x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
        "\n",
        "            # Boîte et ID\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"ID:{track_id}\", (x1, y1-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "        return frame"
      ],
      "metadata": {
        "id": "yZN0-RUuj0X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test sur une Vidéo Spécifique\n",
        "# Initialisation du tracker (personnes seulement)\n",
        "tracker = VideoTracker(\n",
        "    model_path='yolov8n.pt',\n",
        "    classes=[0],  # 0=personne\n",
        "    conf_threshold=0.5\n",
        ")\n",
        "\n",
        "# Chemin de test\n",
        "test_video = \"/content/drive/MyDrive/fluxcustomer/video/uae-dubai-february-1-2016-people-inside-dubai-mall-in-united-arab-emirates-dub-SBV-306315693-preview.mp4\"\n",
        "output_video = \"/content/drive/MyDrive/fluxcustomer/video/output_tracked.mp4\"\n",
        "\n",
        "# Exécution du tracking\n",
        "stats = tracker.track_video(\n",
        "    input_path=test_video,\n",
        "    output_path=output_video,\n",
        "    show_frames=True,\n",
        "    display_interval=20  # Affiche 1 frame sur 20\n",
        ")\n",
        "\n",
        "# Affichage des statistiques\n",
        "print(\"\\n📊 Statistiques du Tracking:\")\n",
        "print(f\"- Frames traitées: {stats['total_frames']}\")\n",
        "print(f\"- Temps total: {stats['processing_time']:.2f}s\")\n",
        "print(f\"- FPS moyen: {stats['fps']:.2f}\")\n",
        "print(f\"- Vidéo sauvegardée: {output_video}\")\n",
        "\n",
        "# Visualisation du résultat\n",
        "from IPython.display import Video\n",
        "Video(output_video, embed=True, width=800)"
      ],
      "metadata": {
        "id": "diieLKGFj0a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essai 3 traking videos with deepsort and creating the heatmap"
      ],
      "metadata": {
        "id": "KWNJRl63ZhEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics deep-sort-realtime opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydf0Mo2peS-e",
        "outputId": "cfe56cca-726c-4aac-d591-4b5b89c4ebff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.108-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting deep-sort-realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.108-py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.8/974.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, deep-sort-realtime, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed deep-sort-realtime-1.3.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.108 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics deep-sort-realtime opencv-python numpy matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mjyh6sKeTFN",
        "outputId": "0ca92e99-04c5-4a16-ee2d-fb615463ad8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.108)\n",
            "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lister le contenu du dossier\n",
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Data Traking\"\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "print(\"Fichiers dans le dossier :\", files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY9eOSSDZM9S",
        "outputId": "f35116e1-7124-4191-b1d3-1b255247ffd1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fichiers dans le dossier : ['people-are-shopping-in-a-garden-market-in-canada-for-fruits-and-meats-SBV-347710395-preview.mp4', 'season-sale-with-crowd-of-people-on-escalator-in-shopping-mall-SBV-319088788-preview.mp4', 'uae-dubai-february-1-2016-people-inside-dubai-mall-in-united-arab-emirates-dub-SBV-306315693-preview.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyse des Performances (Problèmes Identifiés) Extrême Lenteur du Système (Point Critique)\n",
        "\n",
        "FPS moyen: 1.60 → Inutilisable en temps réel\n",
        "\n",
        "Temps par frame: 630ms → 63x plus lent qu'une performance standard (25 FPS = 40ms/frame)\n",
        "\n",
        "Origine des Problèmes :\n",
        "\n",
        "YOLOv8 non optimisé : Chargement sur CPU au lieu de GPU\n",
        "\n",
        "DeepSORT configuré de façon sous-optimale\n",
        "\n",
        "Absence de batch processing : Traitement frame par frame\n",
        "\n",
        "Affichage systématique : cv2_imshow() ralentit considérablement\n",
        "\n",
        "Conséquences :\n",
        "\n",
        "7.5 minutes pour traiter 12 secondes de vidéo (à 60 FPS)\n",
        "\n",
        "Impossible pour toute application pratique"
      ],
      "metadata": {
        "id": "epZAKVJojN14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from collections import defaultdict\n",
        "from google.colab.patches import cv2_imshow  # Pour l'affichage dans Colab\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3mJMdUOjIND",
        "outputId": "5153b149-93a0-4c4f-8789-cc0d035f5931"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image & Video HeatMap 1**"
      ],
      "metadata": {
        "id": "DlbgU8Q2jlWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Open video\n",
        "video_path = \"/content/drive/MyDrive/Data Traking/people-are-shopping-in-a-garden-market-in-canada-for-fruits-and-meats-SBV-347710395-preview.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get frame properties\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define output video (MP4 with correct codec)\n",
        "output_path = \"heatmap_output.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # mp4 codec\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Accumulate heatmap\n",
        "heatmap_accumulated = np.zeros((frame_height, frame_width), dtype=np.float32)\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % 10 != 0:\n",
        "        continue\n",
        "\n",
        "    with torch.no_grad():\n",
        "        results = model(frame)\n",
        "\n",
        "    # Create temporary heatmap\n",
        "    heatmap = np.zeros((frame_height, frame_width), dtype=np.float32)\n",
        "\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "            conf = float(box.conf[0].cpu().numpy())\n",
        "            class_id = int(box.cls[0].cpu().numpy())\n",
        "\n",
        "            if class_id == 0:\n",
        "                cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "                cv2.circle(heatmap, (cx, cy), 50, conf, -1)\n",
        "\n",
        "    # Accumulate and normalize heatmap\n",
        "    heatmap_accumulated *= 0.95\n",
        "    heatmap_accumulated = cv2.addWeighted(heatmap_accumulated, 0.8, heatmap, 0.2, 0)\n",
        "\n",
        "    heatmap_norm = cv2.normalize(heatmap_accumulated, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    heatmap_color = cv2.applyColorMap(np.uint8(heatmap_norm), cv2.COLORMAP_JET)\n",
        "\n",
        "    # Overlay heatmap on original frame\n",
        "    blended = cv2.addWeighted(frame, 0.6, heatmap_color, 0.4, 0)\n",
        "\n",
        "    out.write(blended)\n",
        "\n",
        "# Clean up\n",
        "cap.release()\n",
        "out.release()\n",
        "#cv2.destroyAllWindows()\n",
        "\n",
        "# Save last frame and visualizations\n",
        "cv2.imwrite(\"heatmap_transparent.png\", heatmap_color)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB))\n",
        "plt.colorbar(label=\"Densité des clients\")\n",
        "plt.title(\"Heatmap de la Densité des Clients\")\n",
        "plt.axis(\"off\")\n",
        "plt.savefig(\"heatmap_transparent_visual.png\")\n",
        "\n",
        "# Download files\n",
        "print(\"✅ Fichier généré correctement.\")\n",
        "files.download(\"heatmap_output.mp4\")\n",
        "files.download(\"heatmap_transparent.png\")\n",
        "files.download(\"heatmap_transparent_visual.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MEzwI5YNdsZ-",
        "outputId": "304b3f08-63e4-4c69-851d-d01a49d5fe6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 72.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 4 persons, 330.0ms\n",
            "Speed: 21.1ms preprocess, 330.0ms inference, 36.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 232.9ms\n",
            "Speed: 3.9ms preprocess, 232.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 140.3ms\n",
            "Speed: 3.5ms preprocess, 140.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 137.6ms\n",
            "Speed: 3.8ms preprocess, 137.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.7ms\n",
            "Speed: 4.2ms preprocess, 131.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.5ms\n",
            "Speed: 3.7ms preprocess, 131.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 potted plant, 140.0ms\n",
            "Speed: 3.9ms preprocess, 140.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 131.6ms\n",
            "Speed: 4.1ms preprocess, 131.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.7ms\n",
            "Speed: 4.6ms preprocess, 123.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 126.2ms\n",
            "Speed: 4.1ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.3ms\n",
            "Speed: 4.2ms preprocess, 132.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.8ms\n",
            "Speed: 4.5ms preprocess, 124.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.7ms\n",
            "Speed: 3.9ms preprocess, 128.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 146.6ms\n",
            "Speed: 4.5ms preprocess, 146.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.3ms\n",
            "Speed: 3.9ms preprocess, 131.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.5ms\n",
            "Speed: 3.8ms preprocess, 122.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.8ms\n",
            "Speed: 4.1ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 147.2ms\n",
            "Speed: 3.9ms preprocess, 147.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.1ms\n",
            "Speed: 4.2ms preprocess, 130.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 129.0ms\n",
            "Speed: 3.9ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 134.0ms\n",
            "Speed: 4.2ms preprocess, 134.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 133.6ms\n",
            "Speed: 4.5ms preprocess, 133.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 123.6ms\n",
            "Speed: 4.1ms preprocess, 123.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.6ms\n",
            "Speed: 3.0ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.6ms\n",
            "Speed: 3.3ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.9ms\n",
            "Speed: 4.3ms preprocess, 130.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.2ms\n",
            "Speed: 3.6ms preprocess, 131.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 132.1ms\n",
            "Speed: 4.4ms preprocess, 132.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 202.1ms\n",
            "Speed: 11.8ms preprocess, 202.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 191.7ms\n",
            "Speed: 4.2ms preprocess, 191.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 202.8ms\n",
            "Speed: 4.1ms preprocess, 202.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 212.9ms\n",
            "Speed: 4.3ms preprocess, 212.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 196.1ms\n",
            "Speed: 4.1ms preprocess, 196.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 211.9ms\n",
            "Speed: 8.0ms preprocess, 211.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 189.4ms\n",
            "Speed: 4.0ms preprocess, 189.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 204.4ms\n",
            "Speed: 4.3ms preprocess, 204.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 225.8ms\n",
            "Speed: 4.4ms preprocess, 225.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 186.4ms\n",
            "Speed: 3.8ms preprocess, 186.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.6ms\n",
            "Speed: 4.0ms preprocess, 126.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 138.8ms\n",
            "Speed: 4.2ms preprocess, 138.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.3ms\n",
            "Speed: 2.9ms preprocess, 123.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.0ms\n",
            "Speed: 4.7ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.9ms\n",
            "Speed: 3.6ms preprocess, 130.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 137.4ms\n",
            "Speed: 4.4ms preprocess, 137.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 137.8ms\n",
            "Speed: 4.8ms preprocess, 137.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 141.3ms\n",
            "Speed: 5.2ms preprocess, 141.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 140.7ms\n",
            "Speed: 5.5ms preprocess, 140.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 162.1ms\n",
            "Speed: 5.5ms preprocess, 162.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.9ms\n",
            "Speed: 3.3ms preprocess, 123.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.6ms\n",
            "Speed: 4.1ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 129.0ms\n",
            "Speed: 4.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 truck, 130.3ms\n",
            "Speed: 3.6ms preprocess, 130.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.3ms\n",
            "Speed: 4.0ms preprocess, 131.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 truck, 128.4ms\n",
            "Speed: 4.3ms preprocess, 128.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 130.6ms\n",
            "Speed: 4.7ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.4ms\n",
            "Speed: 3.9ms preprocess, 129.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.9ms\n",
            "Speed: 5.1ms preprocess, 127.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.2ms\n",
            "Speed: 4.0ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.5ms\n",
            "Speed: 3.9ms preprocess, 125.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 140.0ms\n",
            "Speed: 4.8ms preprocess, 140.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 125.8ms\n",
            "Speed: 4.1ms preprocess, 125.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.3ms\n",
            "Speed: 3.9ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 141.2ms\n",
            "Speed: 4.0ms preprocess, 141.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 140.7ms\n",
            "Speed: 4.3ms preprocess, 140.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.8ms\n",
            "Speed: 3.9ms preprocess, 128.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.3ms\n",
            "Speed: 5.0ms preprocess, 132.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.5ms\n",
            "Speed: 5.8ms preprocess, 128.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 139.0ms\n",
            "Speed: 4.4ms preprocess, 139.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 128.8ms\n",
            "Speed: 3.7ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.8ms\n",
            "Speed: 3.5ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.4ms\n",
            "Speed: 4.0ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 135.2ms\n",
            "Speed: 3.7ms preprocess, 135.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Fichier généré correctement.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0f58092d-9f97-4082-a0e5-b355d9173bbf\", \"heatmap_output.mp4\", 7690110)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aeaaf7ee-a064-4164-bcbf-ff9a5b55940f\", \"heatmap_transparent.png\", 49477)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4fb689ff-46e3-406d-b118-b337c8c53994\", \"heatmap_transparent_visual.png\", 37450)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **simple tracker using object centroids**"
      ],
      "metadata": {
        "id": "EiSo6LPih6D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load YOLOv8\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Video input\n",
        "video_path = \"/content/drive/MyDrive/Data Traking/people-are-shopping-in-a-garden-market-in-canada-for-fruits-and-meats-SBV-347710395-preview.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Output video config\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\"tracking_lines_output.mp4\", fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Object ID counter and tracking data\n",
        "next_id = 0\n",
        "track_history = defaultdict(list)  # {id: [(x, y), ...]}\n",
        "\n",
        "# Euclidean distance function\n",
        "def get_closest_id(center, objects, threshold=50):\n",
        "    for object_id, prev_center in objects.items():\n",
        "        if np.linalg.norm(np.array(center) - np.array(prev_center)) < threshold:\n",
        "            return object_id\n",
        "    return None\n",
        "\n",
        "# Last known locations of tracked objects\n",
        "tracked_objects = {}\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    with torch.no_grad():\n",
        "        results = model(frame)[0]\n",
        "\n",
        "    detections = []\n",
        "    for box in results.boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "        conf = float(box.conf[0].cpu().numpy())\n",
        "        class_id = int(box.cls[0].cpu().numpy())\n",
        "\n",
        "        if class_id == 0:  # Only people\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            detections.append(((x1, y1, x2, y2), (cx, cy)))\n",
        "\n",
        "    updated_objects = {}\n",
        "    for bbox, center in detections:\n",
        "        matched_id = get_closest_id(center, tracked_objects)\n",
        "\n",
        "        if matched_id is None:\n",
        "            matched_id = next_id\n",
        "            next_id += 1\n",
        "\n",
        "        updated_objects[matched_id] = center\n",
        "        track_history[matched_id].append(center)\n",
        "\n",
        "        # Draw bounding box\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "        cv2.putText(frame, f'ID {matched_id}', (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "    # Draw tracking lines\n",
        "    for object_id, centers in track_history.items():\n",
        "        for i in range(1, len(centers)):\n",
        "            cv2.line(frame, centers[i - 1], centers[i], (0, 255, 0), 2)\n",
        "\n",
        "    # Update tracker\n",
        "    tracked_objects = updated_objects.copy()\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\"✅ Tracking video with movement lines saved as tracking_lines_output.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krwdqLGWh66G",
        "outputId": "efe4e9ae-3a6d-4e00-bb94-e9023623898d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 5 persons, 128.9ms\n",
            "Speed: 5.1ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.2ms\n",
            "Speed: 3.9ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.0ms\n",
            "Speed: 5.6ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 135.8ms\n",
            "Speed: 4.5ms preprocess, 135.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.6ms\n",
            "Speed: 3.8ms preprocess, 123.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 137.2ms\n",
            "Speed: 4.3ms preprocess, 137.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.5ms\n",
            "Speed: 3.7ms preprocess, 131.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.7ms\n",
            "Speed: 3.8ms preprocess, 123.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.9ms\n",
            "Speed: 4.1ms preprocess, 125.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 133.4ms\n",
            "Speed: 3.9ms preprocess, 133.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.9ms\n",
            "Speed: 3.6ms preprocess, 131.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.6ms\n",
            "Speed: 3.6ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.7ms\n",
            "Speed: 3.8ms preprocess, 132.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.1ms\n",
            "Speed: 3.9ms preprocess, 127.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 134.9ms\n",
            "Speed: 4.2ms preprocess, 134.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 136.0ms\n",
            "Speed: 3.9ms preprocess, 136.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.6ms\n",
            "Speed: 4.6ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.3ms\n",
            "Speed: 3.7ms preprocess, 123.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 145.8ms\n",
            "Speed: 4.2ms preprocess, 145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.5ms\n",
            "Speed: 3.9ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.7ms\n",
            "Speed: 3.7ms preprocess, 132.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 135.3ms\n",
            "Speed: 3.8ms preprocess, 135.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.1ms\n",
            "Speed: 4.3ms preprocess, 132.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.4ms\n",
            "Speed: 3.7ms preprocess, 130.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 139.9ms\n",
            "Speed: 4.1ms preprocess, 139.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.1ms\n",
            "Speed: 3.9ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 136.4ms\n",
            "Speed: 4.0ms preprocess, 136.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 136.2ms\n",
            "Speed: 5.2ms preprocess, 136.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 potted plant, 127.8ms\n",
            "Speed: 4.6ms preprocess, 127.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.9ms\n",
            "Speed: 4.1ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 169.4ms\n",
            "Speed: 4.1ms preprocess, 169.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.4ms\n",
            "Speed: 4.0ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 potted plant, 129.9ms\n",
            "Speed: 4.6ms preprocess, 129.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 potted plant, 131.7ms\n",
            "Speed: 4.2ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 potted plant, 1 teddy bear, 125.9ms\n",
            "Speed: 4.5ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.1ms\n",
            "Speed: 4.2ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 138.1ms\n",
            "Speed: 4.1ms preprocess, 138.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 135.7ms\n",
            "Speed: 5.2ms preprocess, 135.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.5ms\n",
            "Speed: 4.0ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.7ms\n",
            "Speed: 4.7ms preprocess, 131.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.0ms\n",
            "Speed: 3.0ms preprocess, 122.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.9ms\n",
            "Speed: 3.6ms preprocess, 128.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.8ms\n",
            "Speed: 3.6ms preprocess, 124.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.5ms\n",
            "Speed: 3.7ms preprocess, 131.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.3ms\n",
            "Speed: 3.7ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 155.8ms\n",
            "Speed: 4.0ms preprocess, 155.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 197.4ms\n",
            "Speed: 3.5ms preprocess, 197.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 190.6ms\n",
            "Speed: 4.4ms preprocess, 190.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 194.3ms\n",
            "Speed: 9.1ms preprocess, 194.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 203.3ms\n",
            "Speed: 4.8ms preprocess, 203.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 201.8ms\n",
            "Speed: 4.7ms preprocess, 201.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 204.3ms\n",
            "Speed: 3.9ms preprocess, 204.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 202.5ms\n",
            "Speed: 4.0ms preprocess, 202.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 199.9ms\n",
            "Speed: 4.8ms preprocess, 199.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 192.3ms\n",
            "Speed: 4.6ms preprocess, 192.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 204.5ms\n",
            "Speed: 3.9ms preprocess, 204.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 206.9ms\n",
            "Speed: 4.9ms preprocess, 206.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 204.3ms\n",
            "Speed: 9.0ms preprocess, 204.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 192.3ms\n",
            "Speed: 4.0ms preprocess, 192.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 201.3ms\n",
            "Speed: 8.0ms preprocess, 201.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 196.8ms\n",
            "Speed: 3.8ms preprocess, 196.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.2ms\n",
            "Speed: 5.5ms preprocess, 128.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.7ms\n",
            "Speed: 3.8ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.6ms\n",
            "Speed: 3.6ms preprocess, 128.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.3ms\n",
            "Speed: 3.5ms preprocess, 123.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.1ms\n",
            "Speed: 4.0ms preprocess, 128.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 129.1ms\n",
            "Speed: 4.2ms preprocess, 129.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 126.7ms\n",
            "Speed: 4.8ms preprocess, 126.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.1ms\n",
            "Speed: 4.0ms preprocess, 128.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 potted plant, 121.6ms\n",
            "Speed: 4.4ms preprocess, 121.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 124.8ms\n",
            "Speed: 4.3ms preprocess, 124.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 potted plant, 127.5ms\n",
            "Speed: 3.7ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 131.7ms\n",
            "Speed: 3.5ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 138.6ms\n",
            "Speed: 4.2ms preprocess, 138.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.3ms\n",
            "Speed: 3.9ms preprocess, 130.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 126.5ms\n",
            "Speed: 4.4ms preprocess, 126.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.9ms\n",
            "Speed: 4.3ms preprocess, 128.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.8ms\n",
            "Speed: 3.6ms preprocess, 126.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.8ms\n",
            "Speed: 4.3ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 142.7ms\n",
            "Speed: 5.0ms preprocess, 142.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 131.2ms\n",
            "Speed: 4.1ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 121.7ms\n",
            "Speed: 3.8ms preprocess, 121.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 128.7ms\n",
            "Speed: 4.0ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 127.3ms\n",
            "Speed: 3.8ms preprocess, 127.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 130.5ms\n",
            "Speed: 4.4ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 147.5ms\n",
            "Speed: 4.2ms preprocess, 147.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 133.1ms\n",
            "Speed: 4.3ms preprocess, 133.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.3ms\n",
            "Speed: 4.2ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.4ms\n",
            "Speed: 3.8ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.1ms\n",
            "Speed: 3.6ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.0ms\n",
            "Speed: 4.0ms preprocess, 131.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 142.4ms\n",
            "Speed: 3.9ms preprocess, 142.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.2ms\n",
            "Speed: 3.8ms preprocess, 129.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.7ms\n",
            "Speed: 4.1ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 132.2ms\n",
            "Speed: 4.0ms preprocess, 132.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 125.6ms\n",
            "Speed: 3.2ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 132.4ms\n",
            "Speed: 4.6ms preprocess, 132.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 136.1ms\n",
            "Speed: 3.9ms preprocess, 136.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 136.4ms\n",
            "Speed: 4.0ms preprocess, 136.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 128.3ms\n",
            "Speed: 4.5ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 135.0ms\n",
            "Speed: 4.0ms preprocess, 135.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 128.4ms\n",
            "Speed: 5.1ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 132.0ms\n",
            "Speed: 4.5ms preprocess, 132.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 132.3ms\n",
            "Speed: 4.1ms preprocess, 132.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.6ms\n",
            "Speed: 4.3ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.3ms\n",
            "Speed: 4.7ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 136.1ms\n",
            "Speed: 4.2ms preprocess, 136.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 133.2ms\n",
            "Speed: 3.9ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 146.1ms\n",
            "Speed: 4.3ms preprocess, 146.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 136.3ms\n",
            "Speed: 4.1ms preprocess, 136.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.8ms\n",
            "Speed: 2.8ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.7ms\n",
            "Speed: 3.6ms preprocess, 126.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.9ms\n",
            "Speed: 4.1ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 134.2ms\n",
            "Speed: 3.9ms preprocess, 134.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.7ms\n",
            "Speed: 4.1ms preprocess, 131.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.1ms\n",
            "Speed: 5.1ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 140.5ms\n",
            "Speed: 4.5ms preprocess, 140.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.8ms\n",
            "Speed: 3.2ms preprocess, 123.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.3ms\n",
            "Speed: 3.8ms preprocess, 131.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.6ms\n",
            "Speed: 8.1ms preprocess, 127.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 184.5ms\n",
            "Speed: 3.9ms preprocess, 184.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 200.0ms\n",
            "Speed: 3.7ms preprocess, 200.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 195.5ms\n",
            "Speed: 3.6ms preprocess, 195.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 198.9ms\n",
            "Speed: 3.7ms preprocess, 198.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 192.9ms\n",
            "Speed: 3.8ms preprocess, 192.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 195.8ms\n",
            "Speed: 3.7ms preprocess, 195.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 192.3ms\n",
            "Speed: 9.4ms preprocess, 192.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 197.3ms\n",
            "Speed: 3.6ms preprocess, 197.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 194.8ms\n",
            "Speed: 3.9ms preprocess, 194.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 193.1ms\n",
            "Speed: 7.1ms preprocess, 193.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 198.9ms\n",
            "Speed: 5.8ms preprocess, 198.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 196.1ms\n",
            "Speed: 3.9ms preprocess, 196.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 204.9ms\n",
            "Speed: 6.2ms preprocess, 204.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 203.0ms\n",
            "Speed: 4.0ms preprocess, 203.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 200.5ms\n",
            "Speed: 4.1ms preprocess, 200.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 174.0ms\n",
            "Speed: 4.0ms preprocess, 174.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.8ms\n",
            "Speed: 4.4ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.4ms\n",
            "Speed: 3.3ms preprocess, 132.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.7ms\n",
            "Speed: 4.5ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 137.6ms\n",
            "Speed: 4.1ms preprocess, 137.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.5ms\n",
            "Speed: 4.2ms preprocess, 126.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.8ms\n",
            "Speed: 4.0ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.1ms\n",
            "Speed: 4.1ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 134.3ms\n",
            "Speed: 4.1ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.3ms\n",
            "Speed: 4.1ms preprocess, 123.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.7ms\n",
            "Speed: 4.2ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 134.5ms\n",
            "Speed: 3.7ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.9ms\n",
            "Speed: 3.9ms preprocess, 123.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.8ms\n",
            "Speed: 5.2ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.1ms\n",
            "Speed: 3.8ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.1ms\n",
            "Speed: 4.9ms preprocess, 127.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.3ms\n",
            "Speed: 3.8ms preprocess, 123.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 138.3ms\n",
            "Speed: 4.2ms preprocess, 138.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.8ms\n",
            "Speed: 3.1ms preprocess, 122.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.8ms\n",
            "Speed: 4.3ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.9ms\n",
            "Speed: 3.2ms preprocess, 129.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 128.4ms\n",
            "Speed: 4.3ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.4ms\n",
            "Speed: 4.4ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 136.1ms\n",
            "Speed: 4.0ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 134.7ms\n",
            "Speed: 4.1ms preprocess, 134.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 135.0ms\n",
            "Speed: 4.0ms preprocess, 135.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.3ms\n",
            "Speed: 4.4ms preprocess, 130.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.6ms\n",
            "Speed: 4.1ms preprocess, 128.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.9ms\n",
            "Speed: 5.3ms preprocess, 125.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 144.0ms\n",
            "Speed: 4.2ms preprocess, 144.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 132.9ms\n",
            "Speed: 3.4ms preprocess, 132.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 131.1ms\n",
            "Speed: 4.9ms preprocess, 131.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 133.3ms\n",
            "Speed: 4.0ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.1ms\n",
            "Speed: 5.8ms preprocess, 124.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.4ms\n",
            "Speed: 3.9ms preprocess, 128.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.2ms\n",
            "Speed: 3.8ms preprocess, 127.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.2ms\n",
            "Speed: 4.6ms preprocess, 130.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.4ms\n",
            "Speed: 4.1ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.3ms\n",
            "Speed: 4.0ms preprocess, 128.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.7ms\n",
            "Speed: 3.6ms preprocess, 123.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.4ms\n",
            "Speed: 4.1ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 121.7ms\n",
            "Speed: 4.0ms preprocess, 121.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 143.9ms\n",
            "Speed: 4.5ms preprocess, 143.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.1ms\n",
            "Speed: 3.5ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.0ms\n",
            "Speed: 4.4ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.2ms\n",
            "Speed: 4.0ms preprocess, 123.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.7ms\n",
            "Speed: 4.0ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 121.6ms\n",
            "Speed: 3.7ms preprocess, 121.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 135.1ms\n",
            "Speed: 4.6ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.3ms\n",
            "Speed: 4.0ms preprocess, 126.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 134.7ms\n",
            "Speed: 4.3ms preprocess, 134.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.0ms\n",
            "Speed: 4.1ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.0ms\n",
            "Speed: 3.7ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.7ms\n",
            "Speed: 3.7ms preprocess, 127.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 139.8ms\n",
            "Speed: 4.0ms preprocess, 139.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.8ms\n",
            "Speed: 3.7ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.0ms\n",
            "Speed: 3.8ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.6ms\n",
            "Speed: 4.9ms preprocess, 129.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.3ms\n",
            "Speed: 4.1ms preprocess, 129.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 131.6ms\n",
            "Speed: 4.1ms preprocess, 131.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 137.3ms\n",
            "Speed: 4.0ms preprocess, 137.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 205.4ms\n",
            "Speed: 3.9ms preprocess, 205.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 212.4ms\n",
            "Speed: 4.2ms preprocess, 212.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 186.7ms\n",
            "Speed: 3.6ms preprocess, 186.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 196.4ms\n",
            "Speed: 3.9ms preprocess, 196.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 205.8ms\n",
            "Speed: 4.1ms preprocess, 205.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 219.3ms\n",
            "Speed: 5.4ms preprocess, 219.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 191.0ms\n",
            "Speed: 3.9ms preprocess, 191.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 196.2ms\n",
            "Speed: 5.5ms preprocess, 196.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 210.2ms\n",
            "Speed: 4.0ms preprocess, 210.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 191.9ms\n",
            "Speed: 12.4ms preprocess, 191.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 183.9ms\n",
            "Speed: 6.3ms preprocess, 183.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 201.3ms\n",
            "Speed: 4.9ms preprocess, 201.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 213.4ms\n",
            "Speed: 4.0ms preprocess, 213.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 206.1ms\n",
            "Speed: 3.9ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 194.9ms\n",
            "Speed: 4.3ms preprocess, 194.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 136.2ms\n",
            "Speed: 3.9ms preprocess, 136.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 131.6ms\n",
            "Speed: 3.1ms preprocess, 131.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 149.9ms\n",
            "Speed: 3.8ms preprocess, 149.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.5ms\n",
            "Speed: 3.4ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.3ms\n",
            "Speed: 3.9ms preprocess, 129.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.3ms\n",
            "Speed: 3.9ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.4ms\n",
            "Speed: 4.1ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 127.6ms\n",
            "Speed: 3.4ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 147.2ms\n",
            "Speed: 4.0ms preprocess, 147.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 142.2ms\n",
            "Speed: 4.6ms preprocess, 142.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 142.7ms\n",
            "Speed: 4.4ms preprocess, 142.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 137.8ms\n",
            "Speed: 5.3ms preprocess, 137.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 147.3ms\n",
            "Speed: 4.8ms preprocess, 147.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 154.9ms\n",
            "Speed: 5.7ms preprocess, 154.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 135.1ms\n",
            "Speed: 6.4ms preprocess, 135.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.4ms\n",
            "Speed: 4.8ms preprocess, 128.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.0ms\n",
            "Speed: 4.0ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 129.9ms\n",
            "Speed: 3.7ms preprocess, 129.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 134.0ms\n",
            "Speed: 4.0ms preprocess, 134.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 136.9ms\n",
            "Speed: 2.9ms preprocess, 136.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.6ms\n",
            "Speed: 7.1ms preprocess, 127.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.4ms\n",
            "Speed: 4.6ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.6ms\n",
            "Speed: 4.7ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.0ms\n",
            "Speed: 3.7ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 134.7ms\n",
            "Speed: 3.8ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.0ms\n",
            "Speed: 4.4ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 134.8ms\n",
            "Speed: 6.0ms preprocess, 134.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.2ms\n",
            "Speed: 3.7ms preprocess, 123.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.0ms\n",
            "Speed: 4.2ms preprocess, 123.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.5ms\n",
            "Speed: 3.9ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.4ms\n",
            "Speed: 4.1ms preprocess, 129.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 horse, 122.5ms\n",
            "Speed: 2.9ms preprocess, 122.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 135.7ms\n",
            "Speed: 4.0ms preprocess, 135.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 121.0ms\n",
            "Speed: 3.5ms preprocess, 121.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.8ms\n",
            "Speed: 3.5ms preprocess, 124.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.5ms\n",
            "Speed: 3.7ms preprocess, 131.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 151.4ms\n",
            "Speed: 3.7ms preprocess, 151.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.5ms\n",
            "Speed: 4.1ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 137.3ms\n",
            "Speed: 3.5ms preprocess, 137.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.0ms\n",
            "Speed: 4.1ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.3ms\n",
            "Speed: 4.9ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 handbags, 125.5ms\n",
            "Speed: 4.0ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 133.6ms\n",
            "Speed: 4.0ms preprocess, 133.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 125.2ms\n",
            "Speed: 4.2ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 141.2ms\n",
            "Speed: 4.3ms preprocess, 141.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.5ms\n",
            "Speed: 4.1ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.4ms\n",
            "Speed: 4.0ms preprocess, 123.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.2ms\n",
            "Speed: 3.3ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 135.5ms\n",
            "Speed: 4.1ms preprocess, 135.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.6ms\n",
            "Speed: 3.7ms preprocess, 126.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 145.4ms\n",
            "Speed: 3.6ms preprocess, 145.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.8ms\n",
            "Speed: 4.0ms preprocess, 122.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.7ms\n",
            "Speed: 4.6ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.0ms\n",
            "Speed: 4.5ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.7ms\n",
            "Speed: 3.9ms preprocess, 132.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.7ms\n",
            "Speed: 3.6ms preprocess, 122.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.8ms\n",
            "Speed: 4.4ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 123.6ms\n",
            "Speed: 4.8ms preprocess, 123.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.1ms\n",
            "Speed: 4.1ms preprocess, 125.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 204.6ms\n",
            "Speed: 4.0ms preprocess, 204.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 201.1ms\n",
            "Speed: 4.2ms preprocess, 201.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 202.8ms\n",
            "Speed: 3.9ms preprocess, 202.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 189.0ms\n",
            "Speed: 4.1ms preprocess, 189.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 196.1ms\n",
            "Speed: 4.0ms preprocess, 196.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 192.4ms\n",
            "Speed: 6.7ms preprocess, 192.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 200.4ms\n",
            "Speed: 5.6ms preprocess, 200.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 193.4ms\n",
            "Speed: 10.3ms preprocess, 193.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 212.1ms\n",
            "Speed: 4.3ms preprocess, 212.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 203.2ms\n",
            "Speed: 4.1ms preprocess, 203.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 188.9ms\n",
            "Speed: 3.9ms preprocess, 188.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 204.7ms\n",
            "Speed: 3.8ms preprocess, 204.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 200.0ms\n",
            "Speed: 4.4ms preprocess, 200.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 211.6ms\n",
            "Speed: 6.4ms preprocess, 211.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 198.7ms\n",
            "Speed: 3.9ms preprocess, 198.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 157.0ms\n",
            "Speed: 5.5ms preprocess, 157.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.0ms\n",
            "Speed: 4.2ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 137.0ms\n",
            "Speed: 3.8ms preprocess, 137.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.1ms\n",
            "Speed: 3.8ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.2ms\n",
            "Speed: 3.8ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.8ms\n",
            "Speed: 3.9ms preprocess, 123.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 136.5ms\n",
            "Speed: 4.8ms preprocess, 136.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.7ms\n",
            "Speed: 3.6ms preprocess, 131.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 135.6ms\n",
            "Speed: 4.1ms preprocess, 135.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 127.9ms\n",
            "Speed: 3.9ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.2ms\n",
            "Speed: 4.0ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 121.2ms\n",
            "Speed: 3.1ms preprocess, 121.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 133.5ms\n",
            "Speed: 4.0ms preprocess, 133.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.3ms\n",
            "Speed: 3.0ms preprocess, 122.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.7ms\n",
            "Speed: 3.9ms preprocess, 130.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.5ms\n",
            "Speed: 4.1ms preprocess, 124.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.3ms\n",
            "Speed: 3.9ms preprocess, 124.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.2ms\n",
            "Speed: 4.4ms preprocess, 125.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 139.1ms\n",
            "Speed: 4.0ms preprocess, 139.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.9ms\n",
            "Speed: 4.0ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.7ms\n",
            "Speed: 4.2ms preprocess, 127.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 133.4ms\n",
            "Speed: 4.3ms preprocess, 133.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.7ms\n",
            "Speed: 4.2ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.7ms\n",
            "Speed: 4.6ms preprocess, 123.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 136.6ms\n",
            "Speed: 4.2ms preprocess, 136.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 135.9ms\n",
            "Speed: 4.2ms preprocess, 135.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 132.2ms\n",
            "Speed: 4.1ms preprocess, 132.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.8ms\n",
            "Speed: 3.9ms preprocess, 129.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.1ms\n",
            "Speed: 3.9ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 123.1ms\n",
            "Speed: 3.5ms preprocess, 123.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.6ms\n",
            "Speed: 3.8ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 121.7ms\n",
            "Speed: 3.9ms preprocess, 121.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 132.7ms\n",
            "Speed: 4.2ms preprocess, 132.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.1ms\n",
            "Speed: 3.9ms preprocess, 130.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.3ms\n",
            "Speed: 4.7ms preprocess, 130.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.7ms\n",
            "Speed: 4.0ms preprocess, 124.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.3ms\n",
            "Speed: 4.1ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 141.6ms\n",
            "Speed: 3.2ms preprocess, 141.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 136.2ms\n",
            "Speed: 5.7ms preprocess, 136.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.7ms\n",
            "Speed: 4.4ms preprocess, 128.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.7ms\n",
            "Speed: 4.0ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.0ms\n",
            "Speed: 3.9ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.4ms\n",
            "Speed: 4.2ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 139.5ms\n",
            "Speed: 4.0ms preprocess, 139.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.2ms\n",
            "Speed: 3.7ms preprocess, 127.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.0ms\n",
            "Speed: 4.2ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.1ms\n",
            "Speed: 7.6ms preprocess, 126.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.3ms\n",
            "Speed: 3.4ms preprocess, 122.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.8ms\n",
            "Speed: 4.7ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 137.9ms\n",
            "Speed: 4.7ms preprocess, 137.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 135.8ms\n",
            "Speed: 4.1ms preprocess, 135.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.4ms\n",
            "Speed: 4.0ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.9ms\n",
            "Speed: 4.2ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.2ms\n",
            "Speed: 4.3ms preprocess, 122.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.7ms\n",
            "Speed: 3.9ms preprocess, 123.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 137.4ms\n",
            "Speed: 4.0ms preprocess, 137.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.9ms\n",
            "Speed: 4.2ms preprocess, 131.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.5ms\n",
            "Speed: 3.9ms preprocess, 129.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.0ms\n",
            "Speed: 3.8ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.8ms\n",
            "Speed: 3.7ms preprocess, 124.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 184.6ms\n",
            "Speed: 3.8ms preprocess, 184.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 196.7ms\n",
            "Speed: 4.0ms preprocess, 196.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 196.5ms\n",
            "Speed: 4.1ms preprocess, 196.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 187.4ms\n",
            "Speed: 4.1ms preprocess, 187.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 183.4ms\n",
            "Speed: 4.0ms preprocess, 183.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 211.4ms\n",
            "Speed: 4.3ms preprocess, 211.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 200.5ms\n",
            "Speed: 6.0ms preprocess, 200.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 191.9ms\n",
            "Speed: 4.1ms preprocess, 191.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 213.1ms\n",
            "Speed: 4.0ms preprocess, 213.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 212.2ms\n",
            "Speed: 4.0ms preprocess, 212.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 191.5ms\n",
            "Speed: 4.1ms preprocess, 191.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 323.2ms\n",
            "Speed: 4.0ms preprocess, 323.2ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 199.3ms\n",
            "Speed: 14.0ms preprocess, 199.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 200.0ms\n",
            "Speed: 6.2ms preprocess, 200.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 197.0ms\n",
            "Speed: 3.9ms preprocess, 197.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.4ms\n",
            "Speed: 3.9ms preprocess, 123.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.1ms\n",
            "Speed: 4.0ms preprocess, 129.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.6ms\n",
            "Speed: 3.9ms preprocess, 125.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 146.7ms\n",
            "Speed: 5.2ms preprocess, 146.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.3ms\n",
            "Speed: 3.2ms preprocess, 122.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.9ms\n",
            "Speed: 4.1ms preprocess, 129.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.2ms\n",
            "Speed: 3.6ms preprocess, 128.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.6ms\n",
            "Speed: 4.3ms preprocess, 127.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.1ms\n",
            "Speed: 3.7ms preprocess, 128.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 149.9ms\n",
            "Speed: 3.7ms preprocess, 149.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.4ms\n",
            "Speed: 5.4ms preprocess, 131.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.7ms\n",
            "Speed: 4.3ms preprocess, 130.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.6ms\n",
            "Speed: 5.3ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 133.1ms\n",
            "Speed: 4.2ms preprocess, 133.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.8ms\n",
            "Speed: 7.6ms preprocess, 124.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 142.6ms\n",
            "Speed: 4.8ms preprocess, 142.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.7ms\n",
            "Speed: 3.5ms preprocess, 123.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.8ms\n",
            "Speed: 3.9ms preprocess, 123.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.5ms\n",
            "Speed: 3.9ms preprocess, 125.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.0ms\n",
            "Speed: 3.9ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.5ms\n",
            "Speed: 3.9ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 154.5ms\n",
            "Speed: 3.8ms preprocess, 154.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.9ms\n",
            "Speed: 2.9ms preprocess, 125.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.4ms\n",
            "Speed: 3.8ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.1ms\n",
            "Speed: 3.9ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.0ms\n",
            "Speed: 4.6ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.5ms\n",
            "Speed: 2.8ms preprocess, 130.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 139.6ms\n",
            "Speed: 8.0ms preprocess, 139.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.6ms\n",
            "Speed: 6.3ms preprocess, 122.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.1ms\n",
            "Speed: 4.4ms preprocess, 124.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.8ms\n",
            "Speed: 4.3ms preprocess, 123.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 128.3ms\n",
            "Speed: 4.0ms preprocess, 128.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.4ms\n",
            "Speed: 2.9ms preprocess, 126.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 133.8ms\n",
            "Speed: 4.0ms preprocess, 133.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.0ms\n",
            "Speed: 3.8ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.5ms\n",
            "Speed: 3.9ms preprocess, 123.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.2ms\n",
            "Speed: 3.7ms preprocess, 124.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.8ms\n",
            "Speed: 4.0ms preprocess, 126.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.5ms\n",
            "Speed: 4.6ms preprocess, 124.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 132.6ms\n",
            "Speed: 4.1ms preprocess, 132.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 136.4ms\n",
            "Speed: 4.2ms preprocess, 136.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.3ms\n",
            "Speed: 4.0ms preprocess, 123.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 121.7ms\n",
            "Speed: 4.3ms preprocess, 121.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.4ms\n",
            "Speed: 3.7ms preprocess, 127.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.4ms\n",
            "Speed: 3.8ms preprocess, 132.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.6ms\n",
            "Speed: 4.0ms preprocess, 127.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 134.4ms\n",
            "Speed: 2.8ms preprocess, 134.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.8ms\n",
            "Speed: 3.8ms preprocess, 127.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 125.6ms\n",
            "Speed: 3.9ms preprocess, 125.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 134.3ms\n",
            "Speed: 4.2ms preprocess, 134.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.8ms\n",
            "Speed: 4.5ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.9ms\n",
            "Speed: 4.3ms preprocess, 129.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 133.7ms\n",
            "Speed: 4.8ms preprocess, 133.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.6ms\n",
            "Speed: 3.8ms preprocess, 122.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.8ms\n",
            "Speed: 4.0ms preprocess, 124.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.0ms\n",
            "Speed: 3.8ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.3ms\n",
            "Speed: 4.4ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 136.4ms\n",
            "Speed: 4.4ms preprocess, 136.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 132.0ms\n",
            "Speed: 3.7ms preprocess, 132.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 139.5ms\n",
            "Speed: 3.3ms preprocess, 139.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 194.8ms\n",
            "Speed: 3.9ms preprocess, 194.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 197.8ms\n",
            "Speed: 10.1ms preprocess, 197.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 193.1ms\n",
            "Speed: 4.0ms preprocess, 193.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 206.2ms\n",
            "Speed: 4.8ms preprocess, 206.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 191.3ms\n",
            "Speed: 4.3ms preprocess, 191.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 206.7ms\n",
            "Speed: 8.9ms preprocess, 206.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 194.6ms\n",
            "Speed: 5.2ms preprocess, 194.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 204.0ms\n",
            "Speed: 7.3ms preprocess, 204.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 205.2ms\n",
            "Speed: 4.1ms preprocess, 205.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 195.0ms\n",
            "Speed: 4.4ms preprocess, 195.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 193.3ms\n",
            "Speed: 4.0ms preprocess, 193.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 208.7ms\n",
            "Speed: 9.4ms preprocess, 208.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 204.6ms\n",
            "Speed: 4.1ms preprocess, 204.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 200.5ms\n",
            "Speed: 3.9ms preprocess, 200.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 165.9ms\n",
            "Speed: 3.7ms preprocess, 165.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 431.5ms\n",
            "Speed: 12.5ms preprocess, 431.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 189.4ms\n",
            "Speed: 4.2ms preprocess, 189.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 147.4ms\n",
            "Speed: 5.7ms preprocess, 147.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 135.0ms\n",
            "Speed: 3.3ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.4ms\n",
            "Speed: 3.0ms preprocess, 125.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 120.8ms\n",
            "Speed: 4.6ms preprocess, 120.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.5ms\n",
            "Speed: 4.1ms preprocess, 125.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.7ms\n",
            "Speed: 4.1ms preprocess, 126.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.1ms\n",
            "Speed: 4.1ms preprocess, 127.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.0ms\n",
            "Speed: 4.1ms preprocess, 129.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.0ms\n",
            "Speed: 7.4ms preprocess, 124.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 121.5ms\n",
            "Speed: 3.9ms preprocess, 121.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.8ms\n",
            "Speed: 8.5ms preprocess, 127.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.9ms\n",
            "Speed: 3.5ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.8ms\n",
            "Speed: 3.8ms preprocess, 125.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.5ms\n",
            "Speed: 3.8ms preprocess, 128.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.8ms\n",
            "Speed: 3.8ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 130.2ms\n",
            "Speed: 2.9ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 127.7ms\n",
            "Speed: 3.9ms preprocess, 127.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.3ms\n",
            "Speed: 3.7ms preprocess, 128.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.0ms\n",
            "Speed: 3.6ms preprocess, 122.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 124.3ms\n",
            "Speed: 3.9ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 133.5ms\n",
            "Speed: 4.4ms preprocess, 133.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 125.3ms\n",
            "Speed: 4.3ms preprocess, 125.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.4ms\n",
            "Speed: 3.4ms preprocess, 123.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.6ms\n",
            "Speed: 3.4ms preprocess, 124.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 122.4ms\n",
            "Speed: 3.9ms preprocess, 122.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 121.2ms\n",
            "Speed: 4.1ms preprocess, 121.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 132.6ms\n",
            "Speed: 5.0ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.0ms\n",
            "Speed: 3.8ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.9ms\n",
            "Speed: 3.8ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.5ms\n",
            "Speed: 3.9ms preprocess, 126.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 129.3ms\n",
            "Speed: 3.8ms preprocess, 129.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.3ms\n",
            "Speed: 4.5ms preprocess, 124.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 134.5ms\n",
            "Speed: 4.0ms preprocess, 134.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.1ms\n",
            "Speed: 3.4ms preprocess, 125.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 142.2ms\n",
            "Speed: 4.0ms preprocess, 142.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.8ms\n",
            "Speed: 3.0ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 133.0ms\n",
            "Speed: 4.3ms preprocess, 133.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 122.1ms\n",
            "Speed: 2.8ms preprocess, 122.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 134.0ms\n",
            "Speed: 4.1ms preprocess, 134.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.2ms\n",
            "Speed: 6.1ms preprocess, 128.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.8ms\n",
            "Speed: 3.8ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.8ms\n",
            "Speed: 3.9ms preprocess, 129.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.6ms\n",
            "Speed: 4.2ms preprocess, 125.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.6ms\n",
            "Speed: 4.0ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 146.4ms\n",
            "Speed: 4.5ms preprocess, 146.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 135.6ms\n",
            "Speed: 4.1ms preprocess, 135.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.1ms\n",
            "Speed: 3.7ms preprocess, 122.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.8ms\n",
            "Speed: 6.3ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.9ms\n",
            "Speed: 4.1ms preprocess, 122.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.8ms\n",
            "Speed: 3.6ms preprocess, 125.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 138.3ms\n",
            "Speed: 5.5ms preprocess, 138.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.9ms\n",
            "Speed: 5.1ms preprocess, 128.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.4ms\n",
            "Speed: 3.3ms preprocess, 123.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.3ms\n",
            "Speed: 4.7ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 200.3ms\n",
            "Speed: 4.0ms preprocess, 200.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 200.1ms\n",
            "Speed: 3.8ms preprocess, 200.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 192.9ms\n",
            "Speed: 3.9ms preprocess, 192.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 195.0ms\n",
            "Speed: 3.7ms preprocess, 195.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 186.1ms\n",
            "Speed: 4.7ms preprocess, 186.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 196.6ms\n",
            "Speed: 4.0ms preprocess, 196.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 255.7ms\n",
            "Speed: 3.8ms preprocess, 255.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 193.9ms\n",
            "Speed: 4.8ms preprocess, 193.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 190.7ms\n",
            "Speed: 4.0ms preprocess, 190.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 196.5ms\n",
            "Speed: 4.0ms preprocess, 196.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 199.4ms\n",
            "Speed: 5.3ms preprocess, 199.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 truck, 203.4ms\n",
            "Speed: 4.1ms preprocess, 203.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 199.2ms\n",
            "Speed: 4.0ms preprocess, 199.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 201.3ms\n",
            "Speed: 3.9ms preprocess, 201.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 182.7ms\n",
            "Speed: 10.0ms preprocess, 182.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.7ms\n",
            "Speed: 3.9ms preprocess, 130.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 121.5ms\n",
            "Speed: 3.0ms preprocess, 121.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 139.1ms\n",
            "Speed: 3.8ms preprocess, 139.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.6ms\n",
            "Speed: 3.3ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 134.5ms\n",
            "Speed: 4.4ms preprocess, 134.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.9ms\n",
            "Speed: 4.0ms preprocess, 125.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 127.3ms\n",
            "Speed: 4.5ms preprocess, 127.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 125.2ms\n",
            "Speed: 2.9ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.0ms\n",
            "Speed: 4.1ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.8ms\n",
            "Speed: 5.9ms preprocess, 129.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.0ms\n",
            "Speed: 3.2ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.5ms\n",
            "Speed: 3.6ms preprocess, 126.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.0ms\n",
            "Speed: 4.1ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 truck, 123.1ms\n",
            "Speed: 3.6ms preprocess, 123.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 truck, 128.3ms\n",
            "Speed: 4.0ms preprocess, 128.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 truck, 129.9ms\n",
            "Speed: 4.3ms preprocess, 129.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.5ms\n",
            "Speed: 4.0ms preprocess, 128.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.9ms\n",
            "Speed: 9.5ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.7ms\n",
            "Speed: 5.8ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.5ms\n",
            "Speed: 4.8ms preprocess, 122.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.0ms\n",
            "Speed: 3.4ms preprocess, 123.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.6ms\n",
            "Speed: 3.7ms preprocess, 125.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.7ms\n",
            "Speed: 6.6ms preprocess, 123.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 144.2ms\n",
            "Speed: 4.0ms preprocess, 144.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.2ms\n",
            "Speed: 3.1ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.7ms\n",
            "Speed: 2.9ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.8ms\n",
            "Speed: 4.0ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.5ms\n",
            "Speed: 5.1ms preprocess, 131.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.5ms\n",
            "Speed: 4.1ms preprocess, 125.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 133.8ms\n",
            "Speed: 2.9ms preprocess, 133.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.8ms\n",
            "Speed: 4.1ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.0ms\n",
            "Speed: 3.8ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.9ms\n",
            "Speed: 4.0ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 truck, 125.8ms\n",
            "Speed: 4.1ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.6ms\n",
            "Speed: 4.0ms preprocess, 124.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 136.0ms\n",
            "Speed: 3.7ms preprocess, 136.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 129.3ms\n",
            "Speed: 4.4ms preprocess, 129.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 123.6ms\n",
            "Speed: 4.2ms preprocess, 123.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.4ms\n",
            "Speed: 4.1ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.8ms\n",
            "Speed: 3.9ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.3ms\n",
            "Speed: 4.0ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 135.4ms\n",
            "Speed: 2.9ms preprocess, 135.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 123.8ms\n",
            "Speed: 3.8ms preprocess, 123.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.3ms\n",
            "Speed: 3.8ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 132.7ms\n",
            "Speed: 3.8ms preprocess, 132.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 132.0ms\n",
            "Speed: 4.3ms preprocess, 132.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.3ms\n",
            "Speed: 4.4ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 137.0ms\n",
            "Speed: 3.8ms preprocess, 137.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.0ms\n",
            "Speed: 5.5ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.4ms\n",
            "Speed: 4.0ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.0ms\n",
            "Speed: 4.9ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 128.7ms\n",
            "Speed: 4.2ms preprocess, 128.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.6ms\n",
            "Speed: 3.9ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 138.6ms\n",
            "Speed: 4.5ms preprocess, 138.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 121.2ms\n",
            "Speed: 3.5ms preprocess, 121.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.5ms\n",
            "Speed: 3.7ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 125.4ms\n",
            "Speed: 4.2ms preprocess, 125.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.1ms\n",
            "Speed: 7.8ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.3ms\n",
            "Speed: 8.4ms preprocess, 142.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 202.7ms\n",
            "Speed: 5.0ms preprocess, 202.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 193.7ms\n",
            "Speed: 5.5ms preprocess, 193.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 horse, 201.0ms\n",
            "Speed: 4.0ms preprocess, 201.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 horse, 198.4ms\n",
            "Speed: 4.2ms preprocess, 198.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 215.1ms\n",
            "Speed: 3.9ms preprocess, 215.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 195.1ms\n",
            "Speed: 3.8ms preprocess, 195.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 197.7ms\n",
            "Speed: 3.8ms preprocess, 197.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 190.5ms\n",
            "Speed: 7.7ms preprocess, 190.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 198.6ms\n",
            "Speed: 3.8ms preprocess, 198.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 197.7ms\n",
            "Speed: 5.8ms preprocess, 197.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 188.6ms\n",
            "Speed: 5.2ms preprocess, 188.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 200.3ms\n",
            "Speed: 6.8ms preprocess, 200.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 194.6ms\n",
            "Speed: 4.4ms preprocess, 194.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 260.4ms\n",
            "Speed: 3.8ms preprocess, 260.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 310.3ms\n",
            "Speed: 4.8ms preprocess, 310.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 231.2ms\n",
            "Speed: 14.9ms preprocess, 231.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 182.3ms\n",
            "Speed: 7.1ms preprocess, 182.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 169.7ms\n",
            "Speed: 4.0ms preprocess, 169.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 163.0ms\n",
            "Speed: 4.2ms preprocess, 163.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 172.7ms\n",
            "Speed: 5.7ms preprocess, 172.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 195.4ms\n",
            "Speed: 4.1ms preprocess, 195.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 160.5ms\n",
            "Speed: 5.4ms preprocess, 160.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 161.8ms\n",
            "Speed: 3.9ms preprocess, 161.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 241.8ms\n",
            "Speed: 20.9ms preprocess, 241.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 197.6ms\n",
            "Speed: 4.5ms preprocess, 197.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 191.3ms\n",
            "Speed: 5.9ms preprocess, 191.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 179.7ms\n",
            "Speed: 4.2ms preprocess, 179.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 171.5ms\n",
            "Speed: 6.3ms preprocess, 171.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 236.1ms\n",
            "Speed: 4.2ms preprocess, 236.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 228.7ms\n",
            "Speed: 4.0ms preprocess, 228.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 212.6ms\n",
            "Speed: 4.6ms preprocess, 212.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 209.4ms\n",
            "Speed: 7.8ms preprocess, 209.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 227.4ms\n",
            "Speed: 4.5ms preprocess, 227.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 184.6ms\n",
            "Speed: 3.8ms preprocess, 184.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.9ms\n",
            "Speed: 4.1ms preprocess, 124.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.6ms\n",
            "Speed: 4.3ms preprocess, 127.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.7ms\n",
            "Speed: 4.0ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.8ms\n",
            "Speed: 4.1ms preprocess, 142.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.0ms\n",
            "Speed: 6.5ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 121.9ms\n",
            "Speed: 2.9ms preprocess, 121.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.7ms\n",
            "Speed: 3.9ms preprocess, 126.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.1ms\n",
            "Speed: 4.1ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 125.8ms\n",
            "Speed: 4.5ms preprocess, 125.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 141.9ms\n",
            "Speed: 4.2ms preprocess, 141.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 131.0ms\n",
            "Speed: 5.5ms preprocess, 131.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 128.3ms\n",
            "Speed: 3.9ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.1ms\n",
            "Speed: 4.5ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.8ms\n",
            "Speed: 4.3ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.0ms\n",
            "Speed: 4.1ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 138.3ms\n",
            "Speed: 2.9ms preprocess, 138.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 129.0ms\n",
            "Speed: 3.9ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 121.8ms\n",
            "Speed: 5.9ms preprocess, 121.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 120.7ms\n",
            "Speed: 4.3ms preprocess, 120.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.5ms\n",
            "Speed: 7.6ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.4ms\n",
            "Speed: 3.8ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 133.1ms\n",
            "Speed: 3.8ms preprocess, 133.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.1ms\n",
            "Speed: 3.7ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.6ms\n",
            "Speed: 3.7ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.3ms\n",
            "Speed: 4.3ms preprocess, 125.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.3ms\n",
            "Speed: 4.1ms preprocess, 132.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.7ms\n",
            "Speed: 4.2ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 136.3ms\n",
            "Speed: 3.8ms preprocess, 136.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.1ms\n",
            "Speed: 4.3ms preprocess, 132.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.2ms\n",
            "Speed: 2.9ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 164.8ms\n",
            "Speed: 4.3ms preprocess, 164.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 203.2ms\n",
            "Speed: 5.8ms preprocess, 203.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 214.6ms\n",
            "Speed: 4.2ms preprocess, 214.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 199.4ms\n",
            "Speed: 4.5ms preprocess, 199.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 197.8ms\n",
            "Speed: 4.9ms preprocess, 197.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 208.1ms\n",
            "Speed: 4.9ms preprocess, 208.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 197.8ms\n",
            "Speed: 4.5ms preprocess, 197.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 200.0ms\n",
            "Speed: 4.2ms preprocess, 200.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 194.2ms\n",
            "Speed: 3.8ms preprocess, 194.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 221.7ms\n",
            "Speed: 3.9ms preprocess, 221.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 210.2ms\n",
            "Speed: 4.0ms preprocess, 210.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 188.8ms\n",
            "Speed: 3.6ms preprocess, 188.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 193.2ms\n",
            "Speed: 6.1ms preprocess, 193.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 334.2ms\n",
            "Speed: 4.8ms preprocess, 334.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 646.1ms\n",
            "Speed: 16.1ms preprocess, 646.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.1ms\n",
            "Speed: 4.2ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 141.5ms\n",
            "Speed: 4.1ms preprocess, 141.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 333.0ms\n",
            "Speed: 3.0ms preprocess, 333.0ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 212.0ms\n",
            "Speed: 4.2ms preprocess, 212.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.0ms\n",
            "Speed: 4.0ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 141.5ms\n",
            "Speed: 5.5ms preprocess, 141.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.7ms\n",
            "Speed: 3.0ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 157.2ms\n",
            "Speed: 3.9ms preprocess, 157.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.0ms\n",
            "Speed: 3.3ms preprocess, 130.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 125.9ms\n",
            "Speed: 3.9ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.3ms\n",
            "Speed: 3.7ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.5ms\n",
            "Speed: 3.8ms preprocess, 128.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.1ms\n",
            "Speed: 3.2ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.4ms\n",
            "Speed: 4.1ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.6ms\n",
            "Speed: 4.1ms preprocess, 127.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.2ms\n",
            "Speed: 4.3ms preprocess, 126.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.6ms\n",
            "Speed: 4.4ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 134.1ms\n",
            "Speed: 6.5ms preprocess, 134.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.1ms\n",
            "Speed: 6.8ms preprocess, 130.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 124.6ms\n",
            "Speed: 6.6ms preprocess, 124.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.2ms\n",
            "Speed: 4.3ms preprocess, 131.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.4ms\n",
            "Speed: 4.0ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.4ms\n",
            "Speed: 4.4ms preprocess, 122.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 134.7ms\n",
            "Speed: 4.1ms preprocess, 134.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.0ms\n",
            "Speed: 4.0ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.1ms\n",
            "Speed: 4.1ms preprocess, 131.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.6ms\n",
            "Speed: 3.9ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.5ms\n",
            "Speed: 4.0ms preprocess, 129.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.8ms\n",
            "Speed: 5.6ms preprocess, 123.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 138.6ms\n",
            "Speed: 2.9ms preprocess, 138.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 132.9ms\n",
            "Speed: 5.1ms preprocess, 132.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.2ms\n",
            "Speed: 4.4ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.1ms\n",
            "Speed: 4.0ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.3ms\n",
            "Speed: 3.5ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.3ms\n",
            "Speed: 4.0ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 139.9ms\n",
            "Speed: 8.7ms preprocess, 139.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.2ms\n",
            "Speed: 4.1ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 136.0ms\n",
            "Speed: 4.3ms preprocess, 136.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.8ms\n",
            "Speed: 3.2ms preprocess, 126.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 131.5ms\n",
            "Speed: 4.4ms preprocess, 131.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 123.1ms\n",
            "Speed: 4.0ms preprocess, 123.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 133.7ms\n",
            "Speed: 7.9ms preprocess, 133.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.9ms\n",
            "Speed: 3.6ms preprocess, 126.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.2ms\n",
            "Speed: 4.1ms preprocess, 131.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 134.2ms\n",
            "Speed: 3.6ms preprocess, 134.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 124.8ms\n",
            "Speed: 3.9ms preprocess, 124.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.5ms\n",
            "Speed: 4.7ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 145.5ms\n",
            "Speed: 6.9ms preprocess, 145.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.8ms\n",
            "Speed: 3.4ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.6ms\n",
            "Speed: 4.8ms preprocess, 128.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.1ms\n",
            "Speed: 3.7ms preprocess, 126.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 124.7ms\n",
            "Speed: 4.1ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 120.8ms\n",
            "Speed: 2.8ms preprocess, 120.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.2ms\n",
            "Speed: 3.6ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 136.1ms\n",
            "Speed: 3.9ms preprocess, 136.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 196.5ms\n",
            "Speed: 3.8ms preprocess, 196.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 200.8ms\n",
            "Speed: 4.0ms preprocess, 200.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 209.0ms\n",
            "Speed: 6.0ms preprocess, 209.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 200.5ms\n",
            "Speed: 4.1ms preprocess, 200.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 186.3ms\n",
            "Speed: 8.6ms preprocess, 186.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 196.3ms\n",
            "Speed: 7.1ms preprocess, 196.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 213.4ms\n",
            "Speed: 3.9ms preprocess, 213.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 196.0ms\n",
            "Speed: 7.4ms preprocess, 196.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 194.4ms\n",
            "Speed: 3.5ms preprocess, 194.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 190.1ms\n",
            "Speed: 3.8ms preprocess, 190.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 186.6ms\n",
            "Speed: 3.9ms preprocess, 186.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 217.8ms\n",
            "Speed: 3.9ms preprocess, 217.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 194.1ms\n",
            "Speed: 3.8ms preprocess, 194.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 202.6ms\n",
            "Speed: 4.6ms preprocess, 202.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 198.5ms\n",
            "Speed: 3.7ms preprocess, 198.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 151.6ms\n",
            "Speed: 7.2ms preprocess, 151.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.2ms\n",
            "Speed: 3.4ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 120.3ms\n",
            "Speed: 3.1ms preprocess, 120.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.1ms\n",
            "Speed: 3.8ms preprocess, 130.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.9ms\n",
            "Speed: 3.9ms preprocess, 127.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.5ms\n",
            "Speed: 3.9ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 134.5ms\n",
            "Speed: 4.9ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Tracking video with movement lines saved as tracking_lines_output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"tracking_lines_output.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "odKzRj4ajyGR",
        "outputId": "ca50caea-cf80-49f2-a9c7-ac1fa06cde5b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9fb9d07e-067b-4f93-b564-a9d191a6f7d8\", \"tracking_lines_output.mp4\", 59730787)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exporting the data to an Excel file"
      ],
      "metadata": {
        "id": "DkXRFtqykxjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What You’ll Export==>\n",
        "Each row in the Excel will include:\n",
        "\n",
        "1-Frame Number\n",
        "\n",
        "2- Object ID\n",
        "\n",
        "3- X, Y position (center of person)\n",
        "\n",
        "4- Total Steps\n",
        "\n",
        "5- trajectory length"
      ],
      "metadata": {
        "id": "UDGtzkf8lJLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywMfQo7blIqb",
        "outputId": "876bc576-fd4e-4ae6-baa6-0396b6162f8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "# Load YOLOv8\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Video input\n",
        "video_path = \"/content/drive/MyDrive/Data Traking/people-are-shopping-in-a-garden-market-in-canada-for-fruits-and-meats-SBV-347710395-preview.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Output video config\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\"tracking_lines_output.mp4\", fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Tracker data\n",
        "next_id = 0\n",
        "track_history = defaultdict(list)        # {id: [(x, y), ...]}\n",
        "trajectory_lengths = defaultdict(float)  # {id: total_distance}\n",
        "tracked_objects = {}\n",
        "\n",
        "# Excel export list\n",
        "export_data = []\n",
        "\n",
        "# Euclidean distance\n",
        "def euclidean(p1, p2):\n",
        "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
        "\n",
        "def get_closest_id(center, objects, threshold=50):\n",
        "    for object_id, prev_center in objects.items():\n",
        "        if euclidean(center, prev_center) < threshold:\n",
        "            return object_id\n",
        "    return None\n",
        "\n",
        "frame_number = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_number += 1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        results = model(frame)[0]\n",
        "\n",
        "    detections = []\n",
        "    for box in results.boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "        class_id = int(box.cls[0].cpu().numpy())\n",
        "\n",
        "        if class_id == 0:  # Person\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            detections.append(((x1, y1, x2, y2), (cx, cy)))\n",
        "\n",
        "    updated_objects = {}\n",
        "    for bbox, center in detections:\n",
        "        matched_id = get_closest_id(center, tracked_objects)\n",
        "\n",
        "        if matched_id is None:\n",
        "            matched_id = next_id\n",
        "            next_id += 1\n",
        "\n",
        "        updated_objects[matched_id] = center\n",
        "\n",
        "        # Update track history and distance\n",
        "        history = track_history[matched_id]\n",
        "        if history:\n",
        "            last_point = history[-1]\n",
        "            dist = euclidean(center, last_point)\n",
        "            trajectory_lengths[matched_id] += dist\n",
        "\n",
        "        track_history[matched_id].append(center)\n",
        "\n",
        "        # Save data for Excel\n",
        "        export_data.append({\n",
        "            \"Frame\": frame_number,\n",
        "            \"ID\": matched_id,\n",
        "            \"X\": center[0],\n",
        "            \"Y\": center[1],\n",
        "            \"Total Steps\": len(track_history[matched_id]),\n",
        "            \"Trajectory Length\": round(trajectory_lengths[matched_id], 2)\n",
        "        })\n",
        "\n",
        "        # Draw visuals\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "        cv2.putText(frame, f'ID {matched_id}', (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "    # Draw tracking lines\n",
        "    for object_id, centers in track_history.items():\n",
        "        for i in range(1, len(centers)):\n",
        "            cv2.line(frame, centers[i - 1], centers[i], (0, 255, 0), 2)\n",
        "\n",
        "    tracked_objects = updated_objects.copy()\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Export to Excel\n",
        "df = pd.DataFrame(export_data)\n",
        "excel_path = \"tracking_data_with_steps.xlsx\"\n",
        "df.to_excel(excel_path, index=False)\n",
        "print(f\"Excel with trajectory data saved: {excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_XS1yJtk7nJ",
        "outputId": "c68e31d1-bbd1-476f-b1d2-e890e1e9ef0a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 5 persons, 131.4ms\n",
            "Speed: 5.9ms preprocess, 131.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 143.1ms\n",
            "Speed: 5.0ms preprocess, 143.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.7ms\n",
            "Speed: 5.4ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.8ms\n",
            "Speed: 4.6ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.3ms\n",
            "Speed: 4.3ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.6ms\n",
            "Speed: 3.8ms preprocess, 122.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 135.1ms\n",
            "Speed: 3.8ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 139.1ms\n",
            "Speed: 4.1ms preprocess, 139.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 121.2ms\n",
            "Speed: 3.8ms preprocess, 121.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.2ms\n",
            "Speed: 4.0ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.4ms\n",
            "Speed: 3.5ms preprocess, 130.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.2ms\n",
            "Speed: 4.1ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.6ms\n",
            "Speed: 4.6ms preprocess, 124.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 134.9ms\n",
            "Speed: 3.6ms preprocess, 134.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.2ms\n",
            "Speed: 9.1ms preprocess, 132.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.7ms\n",
            "Speed: 3.7ms preprocess, 124.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 192.9ms\n",
            "Speed: 3.5ms preprocess, 192.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 195.1ms\n",
            "Speed: 5.6ms preprocess, 195.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 208.6ms\n",
            "Speed: 4.1ms preprocess, 208.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 191.9ms\n",
            "Speed: 4.1ms preprocess, 191.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 195.5ms\n",
            "Speed: 4.1ms preprocess, 195.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 199.5ms\n",
            "Speed: 4.2ms preprocess, 199.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 216.6ms\n",
            "Speed: 4.1ms preprocess, 216.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 189.4ms\n",
            "Speed: 4.3ms preprocess, 189.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 191.0ms\n",
            "Speed: 3.9ms preprocess, 191.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 194.8ms\n",
            "Speed: 6.8ms preprocess, 194.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 196.4ms\n",
            "Speed: 7.5ms preprocess, 196.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 199.0ms\n",
            "Speed: 5.5ms preprocess, 199.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 potted plant, 202.0ms\n",
            "Speed: 5.9ms preprocess, 202.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 198.9ms\n",
            "Speed: 4.3ms preprocess, 198.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 201.0ms\n",
            "Speed: 12.7ms preprocess, 201.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 185.5ms\n",
            "Speed: 3.9ms preprocess, 185.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 potted plant, 124.3ms\n",
            "Speed: 3.9ms preprocess, 124.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 potted plant, 131.0ms\n",
            "Speed: 3.9ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 potted plant, 1 teddy bear, 130.6ms\n",
            "Speed: 3.7ms preprocess, 130.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 137.2ms\n",
            "Speed: 3.5ms preprocess, 137.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.2ms\n",
            "Speed: 3.8ms preprocess, 126.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 136.0ms\n",
            "Speed: 4.0ms preprocess, 136.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.9ms\n",
            "Speed: 5.9ms preprocess, 122.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.8ms\n",
            "Speed: 4.1ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.6ms\n",
            "Speed: 3.8ms preprocess, 129.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.9ms\n",
            "Speed: 4.2ms preprocess, 125.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.0ms\n",
            "Speed: 4.3ms preprocess, 124.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 139.0ms\n",
            "Speed: 4.3ms preprocess, 139.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.6ms\n",
            "Speed: 5.0ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.9ms\n",
            "Speed: 4.0ms preprocess, 131.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 134.8ms\n",
            "Speed: 3.6ms preprocess, 134.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.2ms\n",
            "Speed: 5.7ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 127.4ms\n",
            "Speed: 6.6ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 140.9ms\n",
            "Speed: 3.9ms preprocess, 140.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.7ms\n",
            "Speed: 4.0ms preprocess, 123.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 135.0ms\n",
            "Speed: 4.7ms preprocess, 135.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.6ms\n",
            "Speed: 3.4ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.5ms\n",
            "Speed: 4.5ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.1ms\n",
            "Speed: 4.3ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.0ms\n",
            "Speed: 4.1ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.6ms\n",
            "Speed: 3.9ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.4ms\n",
            "Speed: 4.2ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.9ms\n",
            "Speed: 4.2ms preprocess, 130.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.0ms\n",
            "Speed: 3.5ms preprocess, 131.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.5ms\n",
            "Speed: 3.9ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.0ms\n",
            "Speed: 4.0ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.3ms\n",
            "Speed: 3.8ms preprocess, 132.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 134.7ms\n",
            "Speed: 3.6ms preprocess, 134.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.5ms\n",
            "Speed: 3.9ms preprocess, 129.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.1ms\n",
            "Speed: 4.4ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 130.4ms\n",
            "Speed: 4.6ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 123.0ms\n",
            "Speed: 3.9ms preprocess, 123.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 138.3ms\n",
            "Speed: 4.2ms preprocess, 138.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 potted plant, 124.6ms\n",
            "Speed: 3.5ms preprocess, 124.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 131.6ms\n",
            "Speed: 3.5ms preprocess, 131.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 potted plant, 128.1ms\n",
            "Speed: 3.6ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 135.3ms\n",
            "Speed: 3.9ms preprocess, 135.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 122.3ms\n",
            "Speed: 3.2ms preprocess, 122.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 137.8ms\n",
            "Speed: 4.1ms preprocess, 137.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 131.7ms\n",
            "Speed: 4.1ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 143.7ms\n",
            "Speed: 3.6ms preprocess, 143.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 133.2ms\n",
            "Speed: 5.3ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 136.2ms\n",
            "Speed: 4.1ms preprocess, 136.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 129.4ms\n",
            "Speed: 4.1ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 137.9ms\n",
            "Speed: 4.0ms preprocess, 137.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 128.3ms\n",
            "Speed: 3.6ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 141.0ms\n",
            "Speed: 6.1ms preprocess, 141.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 125.3ms\n",
            "Speed: 4.2ms preprocess, 125.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 123.0ms\n",
            "Speed: 4.0ms preprocess, 123.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 122.4ms\n",
            "Speed: 3.7ms preprocess, 122.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 potted plant, 129.3ms\n",
            "Speed: 3.7ms preprocess, 129.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.2ms\n",
            "Speed: 4.3ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 139.7ms\n",
            "Speed: 4.2ms preprocess, 139.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 133.6ms\n",
            "Speed: 3.7ms preprocess, 133.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.3ms\n",
            "Speed: 4.2ms preprocess, 131.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 134.5ms\n",
            "Speed: 3.8ms preprocess, 134.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 207.2ms\n",
            "Speed: 4.0ms preprocess, 207.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 203.8ms\n",
            "Speed: 5.8ms preprocess, 203.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 197.4ms\n",
            "Speed: 7.4ms preprocess, 197.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 191.8ms\n",
            "Speed: 3.9ms preprocess, 191.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 206.9ms\n",
            "Speed: 6.8ms preprocess, 206.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 202.9ms\n",
            "Speed: 4.1ms preprocess, 202.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 205.9ms\n",
            "Speed: 4.0ms preprocess, 205.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 189.5ms\n",
            "Speed: 3.9ms preprocess, 189.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 204.8ms\n",
            "Speed: 3.8ms preprocess, 204.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 204.1ms\n",
            "Speed: 5.0ms preprocess, 204.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 196.9ms\n",
            "Speed: 4.0ms preprocess, 196.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 189.6ms\n",
            "Speed: 5.4ms preprocess, 189.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 203.8ms\n",
            "Speed: 5.0ms preprocess, 203.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 220.5ms\n",
            "Speed: 4.0ms preprocess, 220.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 203.1ms\n",
            "Speed: 3.7ms preprocess, 203.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 127.6ms\n",
            "Speed: 3.6ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.1ms\n",
            "Speed: 4.1ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.2ms\n",
            "Speed: 3.9ms preprocess, 123.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 140.6ms\n",
            "Speed: 3.7ms preprocess, 140.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.5ms\n",
            "Speed: 3.5ms preprocess, 127.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.4ms\n",
            "Speed: 3.7ms preprocess, 132.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.6ms\n",
            "Speed: 4.7ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 154.1ms\n",
            "Speed: 4.3ms preprocess, 154.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.0ms\n",
            "Speed: 3.9ms preprocess, 129.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 147.5ms\n",
            "Speed: 4.1ms preprocess, 147.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.4ms\n",
            "Speed: 4.4ms preprocess, 126.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.5ms\n",
            "Speed: 4.0ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.0ms\n",
            "Speed: 3.6ms preprocess, 124.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 133.3ms\n",
            "Speed: 3.6ms preprocess, 133.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.0ms\n",
            "Speed: 3.7ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 146.7ms\n",
            "Speed: 3.7ms preprocess, 146.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.0ms\n",
            "Speed: 3.8ms preprocess, 129.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.5ms\n",
            "Speed: 4.2ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.9ms\n",
            "Speed: 3.5ms preprocess, 124.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.9ms\n",
            "Speed: 3.8ms preprocess, 132.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 134.5ms\n",
            "Speed: 4.1ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 144.7ms\n",
            "Speed: 4.3ms preprocess, 144.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.1ms\n",
            "Speed: 4.4ms preprocess, 128.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.7ms\n",
            "Speed: 4.3ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.6ms\n",
            "Speed: 3.4ms preprocess, 123.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.4ms\n",
            "Speed: 4.1ms preprocess, 130.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.1ms\n",
            "Speed: 3.9ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 144.7ms\n",
            "Speed: 4.2ms preprocess, 144.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.2ms\n",
            "Speed: 4.1ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.6ms\n",
            "Speed: 3.9ms preprocess, 129.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 124.6ms\n",
            "Speed: 4.0ms preprocess, 124.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.2ms\n",
            "Speed: 4.1ms preprocess, 130.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.7ms\n",
            "Speed: 4.0ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 133.4ms\n",
            "Speed: 3.8ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 136.6ms\n",
            "Speed: 4.8ms preprocess, 136.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.1ms\n",
            "Speed: 3.9ms preprocess, 123.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.0ms\n",
            "Speed: 3.4ms preprocess, 124.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.0ms\n",
            "Speed: 4.2ms preprocess, 131.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.4ms\n",
            "Speed: 3.9ms preprocess, 125.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 133.2ms\n",
            "Speed: 4.2ms preprocess, 133.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 139.5ms\n",
            "Speed: 4.1ms preprocess, 139.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.1ms\n",
            "Speed: 3.8ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.1ms\n",
            "Speed: 3.6ms preprocess, 122.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.4ms\n",
            "Speed: 3.8ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.1ms\n",
            "Speed: 4.0ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.4ms\n",
            "Speed: 8.0ms preprocess, 131.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 140.5ms\n",
            "Speed: 3.1ms preprocess, 140.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 140.8ms\n",
            "Speed: 3.8ms preprocess, 140.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.1ms\n",
            "Speed: 3.9ms preprocess, 124.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 131.8ms\n",
            "Speed: 4.0ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.1ms\n",
            "Speed: 3.9ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.3ms\n",
            "Speed: 5.2ms preprocess, 131.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 143.0ms\n",
            "Speed: 4.1ms preprocess, 143.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.2ms\n",
            "Speed: 3.9ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 122.2ms\n",
            "Speed: 3.6ms preprocess, 122.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.5ms\n",
            "Speed: 5.1ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.5ms\n",
            "Speed: 4.0ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 136.6ms\n",
            "Speed: 3.9ms preprocess, 136.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 142.4ms\n",
            "Speed: 3.0ms preprocess, 142.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 158.4ms\n",
            "Speed: 4.0ms preprocess, 158.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 196.7ms\n",
            "Speed: 4.0ms preprocess, 196.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 198.6ms\n",
            "Speed: 5.8ms preprocess, 198.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 207.0ms\n",
            "Speed: 4.0ms preprocess, 207.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 212.3ms\n",
            "Speed: 7.8ms preprocess, 212.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 202.2ms\n",
            "Speed: 4.1ms preprocess, 202.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 209.2ms\n",
            "Speed: 3.8ms preprocess, 209.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 212.3ms\n",
            "Speed: 4.1ms preprocess, 212.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 198.1ms\n",
            "Speed: 9.9ms preprocess, 198.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 194.1ms\n",
            "Speed: 3.9ms preprocess, 194.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 201.3ms\n",
            "Speed: 6.2ms preprocess, 201.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 204.8ms\n",
            "Speed: 6.7ms preprocess, 204.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 201.3ms\n",
            "Speed: 3.9ms preprocess, 201.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 207.8ms\n",
            "Speed: 4.0ms preprocess, 207.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 204.5ms\n",
            "Speed: 4.3ms preprocess, 204.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 161.9ms\n",
            "Speed: 4.1ms preprocess, 161.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 132.5ms\n",
            "Speed: 4.1ms preprocess, 132.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.4ms\n",
            "Speed: 3.9ms preprocess, 122.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.0ms\n",
            "Speed: 3.2ms preprocess, 130.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 133.4ms\n",
            "Speed: 3.9ms preprocess, 133.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.0ms\n",
            "Speed: 4.5ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.9ms\n",
            "Speed: 3.7ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.6ms\n",
            "Speed: 3.6ms preprocess, 129.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.7ms\n",
            "Speed: 4.5ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.5ms\n",
            "Speed: 4.4ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.5ms\n",
            "Speed: 4.0ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.0ms\n",
            "Speed: 3.7ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.6ms\n",
            "Speed: 4.0ms preprocess, 129.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 130.1ms\n",
            "Speed: 4.4ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 128.2ms\n",
            "Speed: 3.8ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 126.2ms\n",
            "Speed: 3.8ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 135.4ms\n",
            "Speed: 6.5ms preprocess, 135.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 128.2ms\n",
            "Speed: 3.7ms preprocess, 128.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 126.9ms\n",
            "Speed: 3.9ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.2ms\n",
            "Speed: 3.7ms preprocess, 123.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 139.5ms\n",
            "Speed: 3.7ms preprocess, 139.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.6ms\n",
            "Speed: 3.6ms preprocess, 127.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 126.9ms\n",
            "Speed: 4.1ms preprocess, 126.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 127.5ms\n",
            "Speed: 4.1ms preprocess, 127.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 129.0ms\n",
            "Speed: 4.0ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.2ms\n",
            "Speed: 3.2ms preprocess, 123.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 139.4ms\n",
            "Speed: 3.9ms preprocess, 139.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 125.5ms\n",
            "Speed: 3.9ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 133.8ms\n",
            "Speed: 5.4ms preprocess, 133.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 133.0ms\n",
            "Speed: 3.9ms preprocess, 133.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 128.3ms\n",
            "Speed: 4.3ms preprocess, 128.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 123.6ms\n",
            "Speed: 4.3ms preprocess, 123.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 141.3ms\n",
            "Speed: 4.1ms preprocess, 141.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.2ms\n",
            "Speed: 3.3ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 138.2ms\n",
            "Speed: 3.8ms preprocess, 138.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.4ms\n",
            "Speed: 3.7ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 140.1ms\n",
            "Speed: 4.3ms preprocess, 140.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 122.3ms\n",
            "Speed: 4.1ms preprocess, 122.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 140.9ms\n",
            "Speed: 4.1ms preprocess, 140.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.9ms\n",
            "Speed: 3.2ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 135.0ms\n",
            "Speed: 4.1ms preprocess, 135.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.2ms\n",
            "Speed: 3.9ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 132.0ms\n",
            "Speed: 4.2ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 120.9ms\n",
            "Speed: 3.2ms preprocess, 120.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 136.3ms\n",
            "Speed: 4.0ms preprocess, 136.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.8ms\n",
            "Speed: 4.1ms preprocess, 124.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 139.1ms\n",
            "Speed: 4.0ms preprocess, 139.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 128.7ms\n",
            "Speed: 3.8ms preprocess, 128.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 129.3ms\n",
            "Speed: 4.3ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.1ms\n",
            "Speed: 3.7ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.6ms\n",
            "Speed: 3.8ms preprocess, 130.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.3ms\n",
            "Speed: 3.0ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 135.8ms\n",
            "Speed: 3.7ms preprocess, 135.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.9ms\n",
            "Speed: 3.9ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 137.7ms\n",
            "Speed: 4.1ms preprocess, 137.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.7ms\n",
            "Speed: 5.0ms preprocess, 122.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.2ms\n",
            "Speed: 3.4ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 138.8ms\n",
            "Speed: 4.0ms preprocess, 138.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 132.2ms\n",
            "Speed: 4.1ms preprocess, 132.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 133.7ms\n",
            "Speed: 3.9ms preprocess, 133.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 190.0ms\n",
            "Speed: 4.3ms preprocess, 190.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 horse, 197.0ms\n",
            "Speed: 3.7ms preprocess, 197.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 202.3ms\n",
            "Speed: 5.3ms preprocess, 202.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 207.2ms\n",
            "Speed: 3.9ms preprocess, 207.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 322.7ms\n",
            "Speed: 5.7ms preprocess, 322.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 494.4ms\n",
            "Speed: 7.2ms preprocess, 494.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 788.7ms\n",
            "Speed: 8.7ms preprocess, 788.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 579.2ms\n",
            "Speed: 15.4ms preprocess, 579.2ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 519.7ms\n",
            "Speed: 7.8ms preprocess, 519.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 212.6ms\n",
            "Speed: 4.4ms preprocess, 212.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.2ms\n",
            "Speed: 4.0ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 handbags, 208.9ms\n",
            "Speed: 4.1ms preprocess, 208.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 128.8ms\n",
            "Speed: 4.7ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 209.8ms\n",
            "Speed: 3.6ms preprocess, 209.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 351.8ms\n",
            "Speed: 3.5ms preprocess, 351.8ms inference, 22.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 352.2ms\n",
            "Speed: 3.7ms preprocess, 352.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 207.1ms\n",
            "Speed: 5.6ms preprocess, 207.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 224.9ms\n",
            "Speed: 5.7ms preprocess, 224.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 166.5ms\n",
            "Speed: 3.6ms preprocess, 166.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 134.1ms\n",
            "Speed: 4.4ms preprocess, 134.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 185.9ms\n",
            "Speed: 4.1ms preprocess, 185.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 219.8ms\n",
            "Speed: 6.1ms preprocess, 219.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 138.2ms\n",
            "Speed: 4.0ms preprocess, 138.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 210.1ms\n",
            "Speed: 4.0ms preprocess, 210.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 298.4ms\n",
            "Speed: 3.9ms preprocess, 298.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 285.5ms\n",
            "Speed: 3.8ms preprocess, 285.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 254.5ms\n",
            "Speed: 4.0ms preprocess, 254.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 200.7ms\n",
            "Speed: 8.6ms preprocess, 200.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 204.4ms\n",
            "Speed: 3.6ms preprocess, 204.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 201.6ms\n",
            "Speed: 3.4ms preprocess, 201.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 222.1ms\n",
            "Speed: 4.0ms preprocess, 222.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 195.0ms\n",
            "Speed: 3.6ms preprocess, 195.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 204.4ms\n",
            "Speed: 3.9ms preprocess, 204.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 224.3ms\n",
            "Speed: 3.9ms preprocess, 224.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 194.4ms\n",
            "Speed: 3.8ms preprocess, 194.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 202.8ms\n",
            "Speed: 3.9ms preprocess, 202.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 193.4ms\n",
            "Speed: 4.6ms preprocess, 193.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 202.5ms\n",
            "Speed: 3.6ms preprocess, 202.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.9ms\n",
            "Speed: 4.3ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.5ms\n",
            "Speed: 4.3ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.9ms\n",
            "Speed: 5.4ms preprocess, 129.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.0ms\n",
            "Speed: 4.2ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.3ms\n",
            "Speed: 5.1ms preprocess, 131.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.2ms\n",
            "Speed: 4.1ms preprocess, 126.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.8ms\n",
            "Speed: 4.0ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 147.1ms\n",
            "Speed: 3.9ms preprocess, 147.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 213.5ms\n",
            "Speed: 5.7ms preprocess, 213.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 645.9ms\n",
            "Speed: 6.9ms preprocess, 645.9ms inference, 25.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 724.7ms\n",
            "Speed: 4.9ms preprocess, 724.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 531.7ms\n",
            "Speed: 16.3ms preprocess, 531.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 734.6ms\n",
            "Speed: 3.9ms preprocess, 734.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 437.8ms\n",
            "Speed: 4.7ms preprocess, 437.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 385.8ms\n",
            "Speed: 4.4ms preprocess, 385.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 267.8ms\n",
            "Speed: 5.8ms preprocess, 267.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 472.3ms\n",
            "Speed: 9.9ms preprocess, 472.3ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 223.8ms\n",
            "Speed: 3.8ms preprocess, 223.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 347.9ms\n",
            "Speed: 4.3ms preprocess, 347.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 214.7ms\n",
            "Speed: 4.9ms preprocess, 214.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 205.6ms\n",
            "Speed: 3.6ms preprocess, 205.6ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 330.2ms\n",
            "Speed: 5.3ms preprocess, 330.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 236.7ms\n",
            "Speed: 3.9ms preprocess, 236.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 210.0ms\n",
            "Speed: 3.8ms preprocess, 210.0ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.3ms\n",
            "Speed: 4.1ms preprocess, 132.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 147.6ms\n",
            "Speed: 4.1ms preprocess, 147.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.6ms\n",
            "Speed: 4.1ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 136.1ms\n",
            "Speed: 4.1ms preprocess, 136.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.0ms\n",
            "Speed: 3.4ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.4ms\n",
            "Speed: 3.7ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.7ms\n",
            "Speed: 4.1ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 140.9ms\n",
            "Speed: 5.8ms preprocess, 140.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.3ms\n",
            "Speed: 4.0ms preprocess, 129.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 132.9ms\n",
            "Speed: 4.0ms preprocess, 132.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 167.7ms\n",
            "Speed: 5.5ms preprocess, 167.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 125.7ms\n",
            "Speed: 2.8ms preprocess, 125.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 274.8ms\n",
            "Speed: 4.9ms preprocess, 274.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.2ms\n",
            "Speed: 4.4ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 256.6ms\n",
            "Speed: 4.7ms preprocess, 256.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 247.2ms\n",
            "Speed: 3.7ms preprocess, 247.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 238.2ms\n",
            "Speed: 7.9ms preprocess, 238.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 217.2ms\n",
            "Speed: 3.8ms preprocess, 217.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 254.0ms\n",
            "Speed: 5.1ms preprocess, 254.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 246.1ms\n",
            "Speed: 3.7ms preprocess, 246.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 204.3ms\n",
            "Speed: 11.3ms preprocess, 204.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 148.9ms\n",
            "Speed: 3.9ms preprocess, 148.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.7ms\n",
            "Speed: 3.7ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.6ms\n",
            "Speed: 3.9ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 155.0ms\n",
            "Speed: 8.4ms preprocess, 155.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.8ms\n",
            "Speed: 4.1ms preprocess, 129.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.8ms\n",
            "Speed: 4.2ms preprocess, 128.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 126.0ms\n",
            "Speed: 3.5ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 122.8ms\n",
            "Speed: 4.1ms preprocess, 122.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.5ms\n",
            "Speed: 3.9ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.4ms\n",
            "Speed: 3.9ms preprocess, 132.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 134.3ms\n",
            "Speed: 3.8ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.2ms\n",
            "Speed: 3.9ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 125.7ms\n",
            "Speed: 3.4ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.4ms\n",
            "Speed: 3.7ms preprocess, 126.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.8ms\n",
            "Speed: 4.9ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.2ms\n",
            "Speed: 4.0ms preprocess, 124.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 216.8ms\n",
            "Speed: 4.0ms preprocess, 216.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 209.6ms\n",
            "Speed: 3.6ms preprocess, 209.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 192.3ms\n",
            "Speed: 3.9ms preprocess, 192.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 204.7ms\n",
            "Speed: 3.9ms preprocess, 204.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 207.8ms\n",
            "Speed: 5.0ms preprocess, 207.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 197.5ms\n",
            "Speed: 5.5ms preprocess, 197.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 195.6ms\n",
            "Speed: 3.8ms preprocess, 195.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 203.9ms\n",
            "Speed: 3.6ms preprocess, 203.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 212.2ms\n",
            "Speed: 4.0ms preprocess, 212.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 192.6ms\n",
            "Speed: 3.9ms preprocess, 192.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 185.9ms\n",
            "Speed: 3.9ms preprocess, 185.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 188.5ms\n",
            "Speed: 8.9ms preprocess, 188.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 224.0ms\n",
            "Speed: 3.9ms preprocess, 224.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 205.8ms\n",
            "Speed: 5.6ms preprocess, 205.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 191.3ms\n",
            "Speed: 4.0ms preprocess, 191.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 172.2ms\n",
            "Speed: 6.5ms preprocess, 172.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 131.3ms\n",
            "Speed: 4.9ms preprocess, 131.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 141.4ms\n",
            "Speed: 4.0ms preprocess, 141.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.6ms\n",
            "Speed: 3.6ms preprocess, 128.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 122.4ms\n",
            "Speed: 3.3ms preprocess, 122.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.0ms\n",
            "Speed: 3.8ms preprocess, 124.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.4ms\n",
            "Speed: 3.9ms preprocess, 131.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 132.1ms\n",
            "Speed: 4.2ms preprocess, 132.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 141.6ms\n",
            "Speed: 4.0ms preprocess, 141.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.1ms\n",
            "Speed: 3.7ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.4ms\n",
            "Speed: 4.3ms preprocess, 128.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 133.6ms\n",
            "Speed: 4.3ms preprocess, 133.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 139.0ms\n",
            "Speed: 4.1ms preprocess, 139.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 132.6ms\n",
            "Speed: 4.4ms preprocess, 132.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 141.6ms\n",
            "Speed: 10.8ms preprocess, 141.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.8ms\n",
            "Speed: 4.8ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.2ms\n",
            "Speed: 3.5ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 201.0ms\n",
            "Speed: 4.0ms preprocess, 201.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 271.6ms\n",
            "Speed: 7.4ms preprocess, 271.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 193.3ms\n",
            "Speed: 3.7ms preprocess, 193.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.1ms\n",
            "Speed: 3.8ms preprocess, 128.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 248.3ms\n",
            "Speed: 4.5ms preprocess, 248.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 200.9ms\n",
            "Speed: 4.3ms preprocess, 200.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 231.6ms\n",
            "Speed: 3.9ms preprocess, 231.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 210.2ms\n",
            "Speed: 7.4ms preprocess, 210.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 199.9ms\n",
            "Speed: 4.3ms preprocess, 199.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.4ms\n",
            "Speed: 4.0ms preprocess, 130.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 212.0ms\n",
            "Speed: 4.0ms preprocess, 212.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 200.8ms\n",
            "Speed: 13.4ms preprocess, 200.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 243.4ms\n",
            "Speed: 4.0ms preprocess, 243.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 203.9ms\n",
            "Speed: 3.7ms preprocess, 203.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 234.7ms\n",
            "Speed: 3.9ms preprocess, 234.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 216.4ms\n",
            "Speed: 4.0ms preprocess, 216.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 165.2ms\n",
            "Speed: 6.3ms preprocess, 165.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 133.2ms\n",
            "Speed: 7.1ms preprocess, 133.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.3ms\n",
            "Speed: 4.1ms preprocess, 142.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.6ms\n",
            "Speed: 4.0ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 130.1ms\n",
            "Speed: 3.9ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 129.0ms\n",
            "Speed: 4.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.6ms\n",
            "Speed: 5.5ms preprocess, 130.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.2ms\n",
            "Speed: 4.1ms preprocess, 128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 143.0ms\n",
            "Speed: 3.9ms preprocess, 143.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.8ms\n",
            "Speed: 3.3ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.6ms\n",
            "Speed: 3.8ms preprocess, 127.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 130.3ms\n",
            "Speed: 4.6ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.0ms\n",
            "Speed: 3.5ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.3ms\n",
            "Speed: 4.5ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 143.2ms\n",
            "Speed: 3.9ms preprocess, 143.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.1ms\n",
            "Speed: 3.6ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.1ms\n",
            "Speed: 3.7ms preprocess, 131.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 195.9ms\n",
            "Speed: 3.9ms preprocess, 195.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 200.5ms\n",
            "Speed: 3.6ms preprocess, 200.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 221.6ms\n",
            "Speed: 3.8ms preprocess, 221.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 200.2ms\n",
            "Speed: 3.9ms preprocess, 200.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 188.2ms\n",
            "Speed: 3.8ms preprocess, 188.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 205.1ms\n",
            "Speed: 4.6ms preprocess, 205.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 198.5ms\n",
            "Speed: 5.3ms preprocess, 198.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 194.2ms\n",
            "Speed: 3.9ms preprocess, 194.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 197.1ms\n",
            "Speed: 3.7ms preprocess, 197.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 193.0ms\n",
            "Speed: 4.1ms preprocess, 193.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 186.9ms\n",
            "Speed: 4.0ms preprocess, 186.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 204.7ms\n",
            "Speed: 7.3ms preprocess, 204.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 207.3ms\n",
            "Speed: 3.9ms preprocess, 207.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 205.9ms\n",
            "Speed: 3.8ms preprocess, 205.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 202.9ms\n",
            "Speed: 7.1ms preprocess, 202.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 190.5ms\n",
            "Speed: 4.5ms preprocess, 190.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 138.0ms\n",
            "Speed: 4.1ms preprocess, 138.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.5ms\n",
            "Speed: 5.0ms preprocess, 128.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 132.9ms\n",
            "Speed: 4.1ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.4ms\n",
            "Speed: 4.3ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.5ms\n",
            "Speed: 4.3ms preprocess, 127.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 138.4ms\n",
            "Speed: 4.2ms preprocess, 138.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.9ms\n",
            "Speed: 4.6ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 132.7ms\n",
            "Speed: 4.4ms preprocess, 132.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.0ms\n",
            "Speed: 4.4ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.8ms\n",
            "Speed: 5.7ms preprocess, 129.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.9ms\n",
            "Speed: 4.2ms preprocess, 130.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 137.3ms\n",
            "Speed: 3.4ms preprocess, 137.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.1ms\n",
            "Speed: 2.8ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.3ms\n",
            "Speed: 4.0ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 134.1ms\n",
            "Speed: 4.0ms preprocess, 134.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.8ms\n",
            "Speed: 3.9ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 132.2ms\n",
            "Speed: 4.2ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 143.4ms\n",
            "Speed: 4.2ms preprocess, 143.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.0ms\n",
            "Speed: 3.4ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.1ms\n",
            "Speed: 4.1ms preprocess, 130.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.2ms\n",
            "Speed: 3.8ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 122.4ms\n",
            "Speed: 2.8ms preprocess, 122.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.1ms\n",
            "Speed: 3.9ms preprocess, 125.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 138.1ms\n",
            "Speed: 3.9ms preprocess, 138.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.9ms\n",
            "Speed: 4.0ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.2ms\n",
            "Speed: 4.3ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 132.1ms\n",
            "Speed: 4.2ms preprocess, 132.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.6ms\n",
            "Speed: 3.9ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 129.1ms\n",
            "Speed: 4.3ms preprocess, 129.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 145.4ms\n",
            "Speed: 4.7ms preprocess, 145.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.4ms\n",
            "Speed: 3.0ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 125.8ms\n",
            "Speed: 4.4ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 136.0ms\n",
            "Speed: 4.2ms preprocess, 136.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.8ms\n",
            "Speed: 3.9ms preprocess, 123.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.7ms\n",
            "Speed: 4.0ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 139.9ms\n",
            "Speed: 3.9ms preprocess, 139.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.8ms\n",
            "Speed: 4.7ms preprocess, 124.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 126.1ms\n",
            "Speed: 2.9ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 130.4ms\n",
            "Speed: 4.0ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.5ms\n",
            "Speed: 3.8ms preprocess, 131.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.0ms\n",
            "Speed: 3.7ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 142.4ms\n",
            "Speed: 3.7ms preprocess, 142.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 123.9ms\n",
            "Speed: 5.2ms preprocess, 123.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 122.3ms\n",
            "Speed: 3.1ms preprocess, 122.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 133.9ms\n",
            "Speed: 4.0ms preprocess, 133.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.3ms\n",
            "Speed: 4.6ms preprocess, 128.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 128.9ms\n",
            "Speed: 3.2ms preprocess, 128.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 149.4ms\n",
            "Speed: 5.0ms preprocess, 149.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.3ms\n",
            "Speed: 4.1ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.6ms\n",
            "Speed: 3.1ms preprocess, 123.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.9ms\n",
            "Speed: 4.1ms preprocess, 131.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.5ms\n",
            "Speed: 5.4ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.3ms\n",
            "Speed: 4.0ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 135.6ms\n",
            "Speed: 3.7ms preprocess, 135.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.7ms\n",
            "Speed: 3.9ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 121.9ms\n",
            "Speed: 2.9ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.3ms\n",
            "Speed: 4.2ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.0ms\n",
            "Speed: 3.9ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 168.3ms\n",
            "Speed: 4.1ms preprocess, 168.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 219.1ms\n",
            "Speed: 3.8ms preprocess, 219.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 194.7ms\n",
            "Speed: 3.8ms preprocess, 194.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 197.6ms\n",
            "Speed: 7.5ms preprocess, 197.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 200.7ms\n",
            "Speed: 5.5ms preprocess, 200.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 207.9ms\n",
            "Speed: 7.3ms preprocess, 207.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 199.4ms\n",
            "Speed: 6.2ms preprocess, 199.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 195.6ms\n",
            "Speed: 4.0ms preprocess, 195.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 201.7ms\n",
            "Speed: 4.0ms preprocess, 201.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 214.7ms\n",
            "Speed: 3.9ms preprocess, 214.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 192.1ms\n",
            "Speed: 3.7ms preprocess, 192.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 193.4ms\n",
            "Speed: 3.6ms preprocess, 193.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 217.9ms\n",
            "Speed: 11.6ms preprocess, 217.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 211.9ms\n",
            "Speed: 3.9ms preprocess, 211.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 207.1ms\n",
            "Speed: 3.9ms preprocess, 207.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 177.6ms\n",
            "Speed: 4.9ms preprocess, 177.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.0ms\n",
            "Speed: 3.0ms preprocess, 132.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.6ms\n",
            "Speed: 4.8ms preprocess, 129.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 155.1ms\n",
            "Speed: 4.2ms preprocess, 155.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.5ms\n",
            "Speed: 4.7ms preprocess, 125.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.5ms\n",
            "Speed: 3.9ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 136.5ms\n",
            "Speed: 3.9ms preprocess, 136.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.4ms\n",
            "Speed: 3.0ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 truck, 128.0ms\n",
            "Speed: 3.7ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 137.3ms\n",
            "Speed: 4.4ms preprocess, 137.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.8ms\n",
            "Speed: 4.0ms preprocess, 129.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.6ms\n",
            "Speed: 4.4ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.5ms\n",
            "Speed: 4.2ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.4ms\n",
            "Speed: 4.2ms preprocess, 132.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 128.7ms\n",
            "Speed: 4.3ms preprocess, 128.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 134.4ms\n",
            "Speed: 3.7ms preprocess, 134.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.1ms\n",
            "Speed: 3.9ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.8ms\n",
            "Speed: 4.5ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 138.0ms\n",
            "Speed: 4.0ms preprocess, 138.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 132.6ms\n",
            "Speed: 3.7ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.5ms\n",
            "Speed: 3.9ms preprocess, 132.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 136.3ms\n",
            "Speed: 4.0ms preprocess, 136.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.5ms\n",
            "Speed: 5.9ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.1ms\n",
            "Speed: 4.6ms preprocess, 128.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 134.8ms\n",
            "Speed: 3.9ms preprocess, 134.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 truck, 139.6ms\n",
            "Speed: 5.3ms preprocess, 139.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 truck, 128.9ms\n",
            "Speed: 2.8ms preprocess, 128.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 truck, 145.4ms\n",
            "Speed: 4.5ms preprocess, 145.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.2ms\n",
            "Speed: 4.1ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 137.7ms\n",
            "Speed: 4.8ms preprocess, 137.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.3ms\n",
            "Speed: 4.2ms preprocess, 132.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 136.0ms\n",
            "Speed: 4.2ms preprocess, 136.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.3ms\n",
            "Speed: 4.2ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 139.6ms\n",
            "Speed: 4.2ms preprocess, 139.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 128.8ms\n",
            "Speed: 4.1ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.8ms\n",
            "Speed: 3.9ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.0ms\n",
            "Speed: 2.9ms preprocess, 131.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.8ms\n",
            "Speed: 3.7ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.1ms\n",
            "Speed: 4.2ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 142.6ms\n",
            "Speed: 4.2ms preprocess, 142.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.4ms\n",
            "Speed: 4.0ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 160.3ms\n",
            "Speed: 4.8ms preprocess, 160.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.8ms\n",
            "Speed: 3.8ms preprocess, 129.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.4ms\n",
            "Speed: 5.1ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.3ms\n",
            "Speed: 4.1ms preprocess, 131.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 truck, 126.9ms\n",
            "Speed: 3.6ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.4ms\n",
            "Speed: 4.4ms preprocess, 131.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.7ms\n",
            "Speed: 5.1ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 133.2ms\n",
            "Speed: 4.0ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 130.2ms\n",
            "Speed: 2.9ms preprocess, 130.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 132.5ms\n",
            "Speed: 4.0ms preprocess, 132.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.6ms\n",
            "Speed: 2.8ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.9ms\n",
            "Speed: 4.0ms preprocess, 132.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 134.5ms\n",
            "Speed: 4.0ms preprocess, 134.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 130.4ms\n",
            "Speed: 3.9ms preprocess, 130.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 133.0ms\n",
            "Speed: 4.7ms preprocess, 133.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 134.1ms\n",
            "Speed: 4.3ms preprocess, 134.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 129.2ms\n",
            "Speed: 4.0ms preprocess, 129.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 200.1ms\n",
            "Speed: 10.3ms preprocess, 200.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 196.8ms\n",
            "Speed: 4.6ms preprocess, 196.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 198.0ms\n",
            "Speed: 3.9ms preprocess, 198.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 206.7ms\n",
            "Speed: 5.0ms preprocess, 206.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 192.8ms\n",
            "Speed: 4.3ms preprocess, 192.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 203.0ms\n",
            "Speed: 3.7ms preprocess, 203.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 211.8ms\n",
            "Speed: 4.5ms preprocess, 211.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 210.7ms\n",
            "Speed: 5.8ms preprocess, 210.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 194.7ms\n",
            "Speed: 4.5ms preprocess, 194.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 203.5ms\n",
            "Speed: 5.2ms preprocess, 203.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 188.3ms\n",
            "Speed: 4.1ms preprocess, 188.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 203.4ms\n",
            "Speed: 3.8ms preprocess, 203.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 192.5ms\n",
            "Speed: 4.1ms preprocess, 192.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 197.1ms\n",
            "Speed: 3.8ms preprocess, 197.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 197.2ms\n",
            "Speed: 6.7ms preprocess, 197.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 horse, 135.5ms\n",
            "Speed: 3.0ms preprocess, 135.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 horse, 124.2ms\n",
            "Speed: 3.3ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.7ms\n",
            "Speed: 3.9ms preprocess, 124.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.1ms\n",
            "Speed: 4.9ms preprocess, 128.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.4ms\n",
            "Speed: 4.8ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 124.6ms\n",
            "Speed: 3.4ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 137.1ms\n",
            "Speed: 4.1ms preprocess, 137.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 132.2ms\n",
            "Speed: 3.2ms preprocess, 132.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.5ms\n",
            "Speed: 3.0ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 131.8ms\n",
            "Speed: 4.2ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 127.2ms\n",
            "Speed: 3.9ms preprocess, 127.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.6ms\n",
            "Speed: 3.9ms preprocess, 127.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.5ms\n",
            "Speed: 3.2ms preprocess, 132.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.9ms\n",
            "Speed: 4.6ms preprocess, 131.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.2ms\n",
            "Speed: 3.6ms preprocess, 126.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.2ms\n",
            "Speed: 4.4ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.5ms\n",
            "Speed: 8.1ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.5ms\n",
            "Speed: 3.8ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.6ms\n",
            "Speed: 3.7ms preprocess, 128.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 131.3ms\n",
            "Speed: 7.2ms preprocess, 131.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 133.2ms\n",
            "Speed: 3.7ms preprocess, 133.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 122.8ms\n",
            "Speed: 3.9ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.1ms\n",
            "Speed: 5.0ms preprocess, 126.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 128.8ms\n",
            "Speed: 3.6ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 126.1ms\n",
            "Speed: 3.4ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 129.6ms\n",
            "Speed: 4.3ms preprocess, 129.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.5ms\n",
            "Speed: 2.9ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.2ms\n",
            "Speed: 4.0ms preprocess, 128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.2ms\n",
            "Speed: 4.0ms preprocess, 127.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 136.7ms\n",
            "Speed: 3.9ms preprocess, 136.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.5ms\n",
            "Speed: 3.8ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.3ms\n",
            "Speed: 3.7ms preprocess, 131.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 132.2ms\n",
            "Speed: 4.1ms preprocess, 132.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.1ms\n",
            "Speed: 4.7ms preprocess, 131.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.5ms\n",
            "Speed: 3.9ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 137.6ms\n",
            "Speed: 3.9ms preprocess, 137.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.9ms\n",
            "Speed: 4.1ms preprocess, 126.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.4ms\n",
            "Speed: 7.0ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.4ms\n",
            "Speed: 4.0ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.1ms\n",
            "Speed: 4.1ms preprocess, 125.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 127.1ms\n",
            "Speed: 4.3ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 125.7ms\n",
            "Speed: 4.2ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 133.0ms\n",
            "Speed: 5.0ms preprocess, 133.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 130.5ms\n",
            "Speed: 4.4ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.0ms\n",
            "Speed: 3.9ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 127.8ms\n",
            "Speed: 4.2ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 130.2ms\n",
            "Speed: 4.2ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 125.7ms\n",
            "Speed: 3.2ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 127.5ms\n",
            "Speed: 3.5ms preprocess, 127.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 126.7ms\n",
            "Speed: 3.7ms preprocess, 126.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.8ms\n",
            "Speed: 3.4ms preprocess, 123.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.9ms\n",
            "Speed: 3.9ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.7ms\n",
            "Speed: 4.4ms preprocess, 130.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 123.0ms\n",
            "Speed: 4.0ms preprocess, 123.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 130.7ms\n",
            "Speed: 4.2ms preprocess, 130.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 147.2ms\n",
            "Speed: 5.2ms preprocess, 147.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.5ms\n",
            "Speed: 4.5ms preprocess, 125.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.3ms\n",
            "Speed: 4.0ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 201.6ms\n",
            "Speed: 3.9ms preprocess, 201.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 200.0ms\n",
            "Speed: 3.7ms preprocess, 200.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 197.9ms\n",
            "Speed: 3.9ms preprocess, 197.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 203.5ms\n",
            "Speed: 4.0ms preprocess, 203.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 194.3ms\n",
            "Speed: 3.9ms preprocess, 194.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 199.1ms\n",
            "Speed: 3.8ms preprocess, 199.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 209.5ms\n",
            "Speed: 3.9ms preprocess, 209.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 195.8ms\n",
            "Speed: 7.2ms preprocess, 195.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 194.4ms\n",
            "Speed: 7.0ms preprocess, 194.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 194.3ms\n",
            "Speed: 4.1ms preprocess, 194.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 210.5ms\n",
            "Speed: 4.6ms preprocess, 210.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 202.0ms\n",
            "Speed: 4.8ms preprocess, 202.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 213.2ms\n",
            "Speed: 4.0ms preprocess, 213.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 195.5ms\n",
            "Speed: 7.4ms preprocess, 195.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 180.3ms\n",
            "Speed: 3.8ms preprocess, 180.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.9ms\n",
            "Speed: 3.1ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.3ms\n",
            "Speed: 3.9ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.9ms\n",
            "Speed: 3.6ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.4ms\n",
            "Speed: 4.9ms preprocess, 131.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 131.8ms\n",
            "Speed: 3.4ms preprocess, 131.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 128.1ms\n",
            "Speed: 4.0ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 130.3ms\n",
            "Speed: 3.9ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.5ms\n",
            "Speed: 3.9ms preprocess, 132.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.9ms\n",
            "Speed: 3.9ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.1ms\n",
            "Speed: 4.1ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 138.3ms\n",
            "Speed: 4.5ms preprocess, 138.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 129.8ms\n",
            "Speed: 3.6ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 139.1ms\n",
            "Speed: 3.8ms preprocess, 139.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 141.7ms\n",
            "Speed: 4.0ms preprocess, 141.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 137.6ms\n",
            "Speed: 4.1ms preprocess, 137.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 127.1ms\n",
            "Speed: 3.5ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 139.6ms\n",
            "Speed: 3.8ms preprocess, 139.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 181.7ms\n",
            "Speed: 3.6ms preprocess, 181.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 205.3ms\n",
            "Speed: 8.1ms preprocess, 205.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 227.0ms\n",
            "Speed: 3.9ms preprocess, 227.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 276.8ms\n",
            "Speed: 3.7ms preprocess, 276.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 371.4ms\n",
            "Speed: 15.8ms preprocess, 371.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 207.5ms\n",
            "Speed: 4.4ms preprocess, 207.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 138.5ms\n",
            "Speed: 3.0ms preprocess, 138.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 124.7ms\n",
            "Speed: 3.2ms preprocess, 124.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 137.2ms\n",
            "Speed: 5.5ms preprocess, 137.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 125.2ms\n",
            "Speed: 3.0ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 127.5ms\n",
            "Speed: 4.1ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 122.8ms\n",
            "Speed: 3.8ms preprocess, 122.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 144.6ms\n",
            "Speed: 4.5ms preprocess, 144.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 131.8ms\n",
            "Speed: 5.5ms preprocess, 131.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 132.8ms\n",
            "Speed: 3.9ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.4ms\n",
            "Speed: 3.4ms preprocess, 123.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 125.6ms\n",
            "Speed: 3.6ms preprocess, 125.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 123.0ms\n",
            "Speed: 3.8ms preprocess, 123.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 137.2ms\n",
            "Speed: 3.7ms preprocess, 137.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 127.3ms\n",
            "Speed: 3.8ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.3ms\n",
            "Speed: 3.6ms preprocess, 129.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.4ms\n",
            "Speed: 6.1ms preprocess, 123.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.9ms\n",
            "Speed: 4.1ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 124.2ms\n",
            "Speed: 3.9ms preprocess, 124.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 147.7ms\n",
            "Speed: 4.2ms preprocess, 147.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 128.0ms\n",
            "Speed: 3.9ms preprocess, 128.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 128.4ms\n",
            "Speed: 3.7ms preprocess, 128.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 127.2ms\n",
            "Speed: 4.1ms preprocess, 127.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 128.0ms\n",
            "Speed: 4.0ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 129.7ms\n",
            "Speed: 5.2ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 140.5ms\n",
            "Speed: 4.3ms preprocess, 140.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 162.6ms\n",
            "Speed: 4.2ms preprocess, 162.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 128.2ms\n",
            "Speed: 3.8ms preprocess, 128.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.1ms\n",
            "Speed: 4.0ms preprocess, 123.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 137.7ms\n",
            "Speed: 4.2ms preprocess, 137.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 209.8ms\n",
            "Speed: 3.7ms preprocess, 209.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 204.6ms\n",
            "Speed: 4.1ms preprocess, 204.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 196.7ms\n",
            "Speed: 4.0ms preprocess, 196.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 189.5ms\n",
            "Speed: 4.2ms preprocess, 189.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 217.1ms\n",
            "Speed: 4.2ms preprocess, 217.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 207.0ms\n",
            "Speed: 5.8ms preprocess, 207.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 196.7ms\n",
            "Speed: 3.8ms preprocess, 196.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 196.2ms\n",
            "Speed: 4.9ms preprocess, 196.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 219.7ms\n",
            "Speed: 4.8ms preprocess, 219.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 193.9ms\n",
            "Speed: 3.7ms preprocess, 193.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 187.3ms\n",
            "Speed: 3.9ms preprocess, 187.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 203.9ms\n",
            "Speed: 3.9ms preprocess, 203.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 209.1ms\n",
            "Speed: 3.8ms preprocess, 209.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 198.8ms\n",
            "Speed: 4.4ms preprocess, 198.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 188.4ms\n",
            "Speed: 8.5ms preprocess, 188.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 131.9ms\n",
            "Speed: 3.2ms preprocess, 131.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 131.0ms\n",
            "Speed: 4.5ms preprocess, 131.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 140.2ms\n",
            "Speed: 3.7ms preprocess, 140.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 130.7ms\n",
            "Speed: 4.1ms preprocess, 130.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 123.9ms\n",
            "Speed: 3.4ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 124.5ms\n",
            "Speed: 3.5ms preprocess, 124.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 121.5ms\n",
            "Speed: 3.5ms preprocess, 121.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 132.8ms\n",
            "Speed: 4.3ms preprocess, 132.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 134.5ms\n",
            "Speed: 4.6ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.2ms\n",
            "Speed: 3.5ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 126.2ms\n",
            "Speed: 4.7ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 127.4ms\n",
            "Speed: 3.9ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 125.9ms\n",
            "Speed: 4.2ms preprocess, 125.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 138.3ms\n",
            "Speed: 4.1ms preprocess, 138.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Excel with trajectory data saved: tracking_data_with_steps.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"tracking_data_with_steps.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nHCdFJOmngcm",
        "outputId": "2facaac6-75a2-4b23-db57-a05165b34958"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cab2b227-a379-4328-9012-80958dbe95c0\", \"tracking_data_with_steps.xlsx\", 115260)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}